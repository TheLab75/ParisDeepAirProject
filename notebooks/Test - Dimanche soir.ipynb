{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1032f8f3",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017b6bf",
   "metadata": {},
   "source": [
    "## (0) Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2b8350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.431318Z",
     "start_time": "2022-12-01T09:52:38.970273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# Checking data types\n",
    "from typing import Dict, List, Tuple, Sequence\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c3240",
   "metadata": {},
   "source": [
    "## (1) 📚 The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402fd55a",
   "metadata": {},
   "source": [
    "### (1.1) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce92c13",
   "metadata": {},
   "source": [
    "💾 Load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db094e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.458779Z",
     "start_time": "2022-12-01T09:52:42.447651Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pollution/inputs/Xy_PA75016.csv',index_col='Date_time')\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a43f0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.472350Z",
     "start_time": "2022-12-01T09:52:42.459953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>ATMO</th>\n",
       "      <th>sin_Month</th>\n",
       "      <th>cos_Month</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>confinement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.688432</td>\n",
       "      <td>-0.290119</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.021622</td>\n",
       "      <td>0.438683</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.272432</td>\n",
       "      <td>-0.402242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.642595</td>\n",
       "      <td>-0.065872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233514</td>\n",
       "      <td>1.335669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>-0.262919</td>\n",
       "      <td>0.228451</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.242467</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>-0.354595</td>\n",
       "      <td>-0.491941</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0.843243</td>\n",
       "      <td>-0.063069</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>0.397838</td>\n",
       "      <td>-0.278907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1208 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PM10       NO2  ATMO  sin_Month  cos_Month   sin_day   cos_day  \\\n",
       "0    -0.688432 -0.290119     0   0.000000        1.0 -0.781831  0.623490   \n",
       "1    -0.021622  0.438683     0   0.000000        1.0  0.000000  1.000000   \n",
       "2    -0.272432 -0.402242     0   0.000000        1.0  0.781831  0.623490   \n",
       "3    -0.642595 -0.065872     0   0.000000        1.0  0.974928 -0.222521   \n",
       "4     0.233514  1.335669     0   0.000000        1.0  0.433884 -0.900969   \n",
       "...        ...       ...   ...        ...        ...       ...       ...   \n",
       "1203 -0.262919  0.228451     0  -0.866025        0.5  0.781831  0.623490   \n",
       "1204  0.281081  0.242467     0  -0.866025        0.5  0.974928 -0.222521   \n",
       "1205 -0.354595 -0.491941     0  -0.866025        0.5  0.433884 -0.900969   \n",
       "1206  0.843243 -0.063069     0  -0.866025        0.5 -0.433884 -0.900969   \n",
       "1207  0.397838 -0.278907     0  -0.866025        0.5 -0.974928 -0.222521   \n",
       "\n",
       "      confinement  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "1203            0  \n",
       "1204            0  \n",
       "1205            0  \n",
       "1206            0  \n",
       "1207            0  \n",
       "\n",
       "[1208 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9f00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "You have dropped O3 with 100.0 % of NA\n",
      "You have dropped SO2 with 40.203520481304786 % of NA\n",
      "DataFrame is processed, you can play with it !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>ATMO</th>\n",
       "      <th>sin_Month</th>\n",
       "      <th>cos_Month</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>confinement</th>\n",
       "      <th>Pollution_peak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.048074</td>\n",
       "      <td>-0.840686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.048074</td>\n",
       "      <td>-0.840686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.048074</td>\n",
       "      <td>-0.840686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.048074</td>\n",
       "      <td>-0.840686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>-0.025605</td>\n",
       "      <td>-0.131895</td>\n",
       "      <td>-0.840686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-09</th>\n",
       "      <td>-0.504979</td>\n",
       "      <td>-0.603390</td>\n",
       "      <td>-0.507353</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10</th>\n",
       "      <td>0.012802</td>\n",
       "      <td>-0.389522</td>\n",
       "      <td>-0.465686</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-11</th>\n",
       "      <td>-0.315789</td>\n",
       "      <td>-0.951002</td>\n",
       "      <td>-1.296569</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12</th>\n",
       "      <td>1.544808</td>\n",
       "      <td>0.395069</td>\n",
       "      <td>-0.205882</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13</th>\n",
       "      <td>1.684211</td>\n",
       "      <td>0.234206</td>\n",
       "      <td>-0.786765</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1775 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PM25      PM10       NO2  ATMO  sin_Month  cos_Month  \\\n",
       "Date_time                                                              \n",
       "2018-01-01 -0.001422 -0.048074 -0.840686     0   0.000000        1.0   \n",
       "2018-01-02 -0.001422 -0.048074 -0.840686     0   0.000000        1.0   \n",
       "2018-01-03 -0.001422 -0.048074 -0.840686     0   0.000000        1.0   \n",
       "2018-01-04 -0.001422 -0.048074 -0.840686     0   0.000000        1.0   \n",
       "2018-01-05 -0.025605 -0.131895 -0.840686     0   0.000000        1.0   \n",
       "...              ...       ...       ...   ...        ...        ...   \n",
       "2022-11-09 -0.504979 -0.603390 -0.507353     0  -0.866025        0.5   \n",
       "2022-11-10  0.012802 -0.389522 -0.465686     0  -0.866025        0.5   \n",
       "2022-11-11 -0.315789 -0.951002 -1.296569     0  -0.866025        0.5   \n",
       "2022-11-12  1.544808  0.395069 -0.205882     1  -0.866025        0.5   \n",
       "2022-11-13  1.684211  0.234206 -0.786765     1  -0.866025        0.5   \n",
       "\n",
       "             sin_day   cos_day  confinement  Pollution_peak  \n",
       "Date_time                                                    \n",
       "2018-01-01 -0.781831  0.623490            0               0  \n",
       "2018-01-02  0.000000  1.000000            0               0  \n",
       "2018-01-03  0.781831  0.623490            0               0  \n",
       "2018-01-04  0.974928 -0.222521            0               0  \n",
       "2018-01-05  0.433884 -0.900969            0               0  \n",
       "...              ...       ...          ...             ...  \n",
       "2022-11-09  0.781831  0.623490            0               0  \n",
       "2022-11-10  0.974928 -0.222521            0               0  \n",
       "2022-11-11  0.433884 -0.900969            0               0  \n",
       "2022-11-12 -0.433884 -0.900969            0               0  \n",
       "2022-11-13 -0.974928 -0.222521            0               0  \n",
       "\n",
       "[1775 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from workflow.preprocessing import preprocess\n",
    "\n",
    "df_16 = pd.read_csv(\"../data/pollution/2_Processed/PA75016.csv\").copy()\n",
    "\n",
    "df_16_preprocessed = preprocess(df_16)\n",
    "\n",
    "\n",
    "df_16_preprocessed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7db67af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:41:26.261342Z",
     "start_time": "2022-12-01T10:41:26.250185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    675\n",
       "2    639\n",
       "0    461\n",
       "Name: ATMO, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_16_preprocessed['ATMO'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce135be",
   "metadata": {},
   "source": [
    "👆 *(Reminders*) This weather dataset is a ***single Time Series*** represented as a DataFrame, i.e. a **2D-array**.\n",
    "- `df.shape = (n_timesteps, n_features)`\n",
    "    - `n_timesteps` $= 1775$k rows  (_~5 years of weather data, from 2018 to 2022 with 1 record every day (mean from hourly records_)\n",
    "    - `n_features` $= 4$ features composed of:\n",
    "        - $1$ <font color=green>**target**</font> (we will use the past values of the temperature as a feature)\n",
    "        - $4$ <font color=orange>**past covariates**</font> (= features which past values are known)\n",
    "        - $0$ <font color=blue>**future covariates**</font> (= features which future values are known, e.g. public holidays)\n",
    "    \n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/time-series-covariates.png?raw=true'>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a13741d",
   "metadata": {},
   "source": [
    "### (1.2) 🌅 The big picture about dealing with Time Series *(reminder)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7d99d",
   "metadata": {},
   "source": [
    "1️⃣ <b>[FOLDS] <u>Cross-Validation in Time Series  </u></b>\n",
    "\n",
    "Starting from this single Time Series:\n",
    "- We will create <font color=\"#c91ac9\">**FOLDS**</font>\n",
    "- <font color=blue>**Train**</font>/<font color=\"#ff8005\">**Evaluate**</font> our LSTM  <font color=\"#c91ac9\">**on each of these different FOLDS**</font> to conclude about <b><u>the robustness of the model</u><b>.\n",
    "    \n",
    "_It is very common to create hundreds of folds in Time Series forecasting, in order to cover all types of external conditions: crash market periods, bull markets, atone markets, etc..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefea409",
   "metadata": {},
   "source": [
    "2️⃣ <b>[TRAIN-TEST SPLIT] <u>Holdout method</u></b>\n",
    "\n",
    "For each <font color=\"#c91ac9\">**FOLD**</font>, we will do a <font color=blue>**TRAIN**</font>-<font color=\"#ff8005\">**TEST**</font> SPLIT to:\n",
    "* <font color=blue>**fit**</font> the model on the <font color=blue>**train**</font> set \n",
    "* <font color=\"#ff8005\">**evaluate**</font> it on the <font color=\"#ff8005\">**test**</font> set\n",
    "\n",
    "_Always split the train set **chronologically** before the test set!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dab76c",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "👇 The first two steps can be summarized in the following image (here, we illustrated a 4-fold temporal cross-validation):\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/time_series_cross_validation.png\" alt=\"Time Series Cross Validation\" width=\"800\" height=\"400\">\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8c0e8",
   "metadata": {},
   "source": [
    "3️⃣ <b>[SEQUENCES] <u>Sampling/Extracting sequences</u></b>\n",
    "\n",
    "\n",
    "After splitting each fold into a <font color=\"blue\">train</font> set and a <font color=\"#ff8005\">test</font> set, it is time to:\n",
    "- 🏋 sample lots of <font color=\"#884dff\"><i>sequences</i></font> $\\color{blue}{(X_i, y_i)}$ on which the model will be <font color=\"blue\">trained</font>\n",
    "- 👩🏻‍🏫 sample lots of <font color=\"#884dff\"><i>sequences</i></font> $\\color{#ff8005}{(X_i, y_i)}$ on which the model will be <font color=\"#ff8005\">evaluated</font>\n",
    "\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> \n",
    "\n",
    "👉 All these <font color=\"#884dff\"><i>sequences</i></font> in the <font color=\"blue\">train</font> set and the <font color=\"#ff8005\">test</font> set will have a common shape `(input_length, n_features)` $ = (14\\times8,19) = (112,19)$.\n",
    "\n",
    "👉 Each <font color=\"#884dff\"><i>sequence</i></font> has a target, the shape of which will be `(output_length, n_targets)` $ = (7\\times8, 1) = (56, 1)$.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/shapes_for_input_sequence_and_ouput_sequence.png\" alt=\"3d arrays time series\" width=\"1200\" height=\"800\"> \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf741737",
   "metadata": {},
   "source": [
    "> 🔥 Open this [**infograph**](https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/big_picture_temporal_data_handling.png)  side-by-side with the notebook for a visual summary! 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6db251",
   "metadata": {},
   "source": [
    "## (2) Adapting the functions from the _\"Predict Temperature\"_ challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcabcfe",
   "metadata": {},
   "source": [
    "### (2.0) Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9c787",
   "metadata": {},
   "source": [
    "🌐 Let's define some ***global variables*** that we will use for our tests everywhere in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7dd75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.476727Z",
     "start_time": "2022-12-01T09:52:42.473608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folds\n",
    "FOLD_LENGTH = 521      # dont 365J Train +  156J Test\n",
    "FOLD_STRIDE = int(209) # sliding each semester - décalage de 209J pour obtenir 7 folds\n",
    "\n",
    "# Temporal Train-Test split\n",
    "TRAIN_TEST_RATIO = 0.7 #70% de train et 30% de test par fold\n",
    "#N_TRAIN = 365 # number_of_sequences_train for each fold_train\n",
    "#N_TEST = 156 # number_of_sequences_test for each fold_test\n",
    "\n",
    "# Inputs\n",
    "N_FEATURES = 4  # 3 polluants + l'ATMO index\n",
    "INPUT_LENGTH = 7 # - Records 1 week ~ 7 days. One week is quite common for air quality  \n",
    "\n",
    "# Outputs\n",
    "TARGET = ['ATMO']\n",
    "TARGET_COLUMN_IDX = 3 # Corresponds to the third column of the df\n",
    "N_TARGETS = 1\n",
    "OUTPUT_LENGTH = N_TARGETS*7 # Predicting one target, the ATMO index for 7 days\n",
    "                              \n",
    "\n",
    "# Additional parameters\n",
    "HORIZON = 1 # - You want to predict this point HORIZON = 1 day after the last known value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9fe462",
   "metadata": {},
   "source": [
    "### (2.1)  🗂 <font color=\"#c91ac9\">FOLDS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565068ec",
   "metadata": {},
   "source": [
    "🎁 **`get_folds`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdfe92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.483227Z",
     "start_time": "2022-12-01T09:52:42.479932Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_folds(df: pd.DataFrame, \n",
    "              fold_length: int,\n",
    "              fold_stride: int) -> List[pd.DataFrame]:\n",
    "    '''\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "    \n",
    "    Returns a list of folds, each as a DataFrame\n",
    "    '''\n",
    "\n",
    "    folds = []\n",
    "    for idx in range(0, len(df), fold_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (idx + fold_length) > len(df):\n",
    "            break\n",
    "        fold = df.iloc[idx:idx + fold_length, :]\n",
    "        folds.append(fold)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf665ae0",
   "metadata": {},
   "source": [
    "👉 Let's generate these <font color=\"#c91ac9\">**FOLDS**</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d5dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.489237Z",
     "start_time": "2022-12-01T09:52:42.484283Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "\n",
    "print(f'The function generated {len(folds)} folds.')\n",
    "print(f'Each fold has a shape equal to {folds[0].shape}.')\n",
    "print(f'The last fold has a shape equal to {folds[-1].shape}.')\n",
    "np.array(folds).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05046f2",
   "metadata": {},
   "source": [
    "7 Folds\n",
    "\n",
    "521 Observations (fold_length)\n",
    "\n",
    "4 features (3 pollutants + 1 target )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06616fd2",
   "metadata": {},
   "source": [
    "🧪 Make sure that the following <font color=green>***assert***</font> doesn't return anything (which means the assertion is correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc6e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.492375Z",
     "start_time": "2022-12-01T09:52:42.490399Z"
    }
   },
   "outputs": [],
   "source": [
    "#assert(folds[0].shape == (180, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8405b1",
   "metadata": {},
   "source": [
    "☝️ This amount of <font color=\"#c91ac9\">**FOLDS**</font> should be enough to cross-validate our model correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cf963d",
   "metadata": {},
   "source": [
    "### (2.2) ✂️  Temporal <font color=blue>Train</font>/<font color=\"#ff8005\">Test</font> Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16704f88",
   "metadata": {},
   "source": [
    "👩🏻‍🏫 Let's <font color=\"#c91ac9\">focus on one fold</font> for the moment, the first one for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9cc332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.500914Z",
     "start_time": "2022-12-01T09:52:42.493491Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = folds[-1]\n",
    "fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a502e",
   "metadata": {},
   "source": [
    "⌚️ We want to ***split this <font color=\"#c91ac9\">fold</font> chronologically*** into a <font color=blue>***fold_train***</font> and a <font color=\"#ff8005\">***fold_test***</font>.\n",
    "\n",
    "*Each of these fold_train and fold_test will contain all the data we need to be able to sample many pairs `(Xi, yi)` in a next step!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4da9b8",
   "metadata": {},
   "source": [
    "#### (2.2.1) 🧑🏻‍🏫 The complexity introduced by the <font color=green>gap</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c554e6",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>⏸ Let's take a <i>quick break</i> from this weather dataset to understand what is a temporal gap.</summary>\n",
    "\n",
    "<hr>\n",
    "\n",
    "🤑 Put yourself in the shoes of a quantitative trader at timesteps $\\color{blue}{1}, \\color{blue}{2}, \\color{blue}{3}, ..., \\color{blue}{10}$.\n",
    "\n",
    "Let's say you are in the <font color=blue>training</font> phase, and you want to stop your training after day `10`:\n",
    "- You have to wait until day `10` to know the real value $y_{10}$, and compare it with the predicted value $\\hat{y}_{10}$ to train the model.\n",
    " \n",
    "Here are the <font color=blue>assumptions about your model</font>:\n",
    "- It is trained on <font color=\"#884dff\"><i>sequences</i></font> with `INPUT_LENGTH = 3`\n",
    "- The goal is to predict `OUTPUT_LENGTH = 1` point in the future\n",
    "- You want to predict this point `HORIZON = 4` days after the last known value.\n",
    "\n",
    "✅ Imagine that your model was trained and put into production\n",
    "\n",
    "❓ <u>On which day can you evaluate the live performance of the model for the first time</u> ❓\n",
    "\n",
    "* You are at day `10`. Hence, the first prediction you can make is for day `10` + `HORIZON` = `14`\n",
    "* You will have to wait until day `14` to see how good was your prediction!\n",
    "    * `y_test_first` = day `14`\n",
    "* You sit IDLE for <font color=green>3</font> days $(11, 12, 13)$\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b88425",
   "metadata": {},
   "source": [
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/train_test_split_with_horizon.jpg?raw=true\" height=500 width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6a500",
   "metadata": {},
   "source": [
    "👉 The <font color=green>gap</font> between the <font color=blue>train</font> and the <font color=orange>test</font> set should be equal to `GAP = HORIZON - 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc8532a",
   "metadata": {},
   "source": [
    "#### (2.2.2) 💻 Adapting the  `train_test_split` function accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2584d",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Temporal <font color=blue>Train</font>/<font color=orange>Test</font> split)** \n",
    "\n",
    "Code the function `train_test_split` down below which:\n",
    "- <i>(inputs)</i> given \n",
    "    - a `fold` (like above), \n",
    "    - a `train_test_ratio` (e.g 0.8) \n",
    "    - an `input_length` (fixed)\n",
    "    - 🆕 a `horizon` (fixed)\n",
    "- <i>(output)</i> returns a tuple (`fold_train`, `fold_test`) of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12901400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.506199Z",
     "start_time": "2022-12-01T09:52:42.502534Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(fold: pd.DataFrame, \n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int, \n",
    "                     horizon: int) -> Tuple[pd.DataFrame]:\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe (fold_train, fold_test)\n",
    "    from which one can sample (X,y) sequences.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))   \n",
    "    '''\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "\n",
    "    # TRAIN SET\n",
    "    # ======================\n",
    "    last_train_idx = round(train_test_ratio * len(fold))\n",
    "    fold_train = fold.iloc[0:last_train_idx, :]\n",
    "\n",
    "    # TEST SET\n",
    "    # ======================\n",
    "    first_test_idx = last_train_idx - input_length\n",
    "    fold_test = fold.iloc[first_test_idx:, :]\n",
    "\n",
    "    return (fold_train, fold_test)\n",
    "\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104e3ef",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Temporal <font color=blue>Train</font>/<font color=orange>Test</font> split for <font color=\"#c91ac9\">one fold </font>)** \n",
    "\n",
    "Split the <font color=\"#c91ac9\">fold #0</font>.\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary><i>Reminders</i></summary>\n",
    "\n",
    "*As a reminder, in  section `(2.0) Global Variables`, we defined*:\n",
    "- *`TRAIN_TEST_RATIO` = 66%* \n",
    "- *`INPUT_LENGTH` = 2 weeks = 112 time steps for each `Xi`, which is quite common in weather forecasting*\n",
    "- *`HORIZON` = 1 day = 8 time steps*\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6acfd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.510156Z",
     "start_time": "2022-12-01T09:52:42.507546Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "(fold_train, fold_test) = train_test_split(fold, \n",
    "                                           TRAIN_TEST_RATIO,\n",
    "                                           INPUT_LENGTH, \n",
    "                                           HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f61d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.513833Z",
     "start_time": "2022-12-01T09:52:42.511215Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_train.shape, fold_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6ccca",
   "metadata": {},
   "source": [
    "🧪 Check that your shapes and your starting/ending points are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7716af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_train.index.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00958153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.517539Z",
     "start_time": "2022-12-01T09:52:42.514903Z"
    }
   },
   "outputs": [],
   "source": [
    "## Double-checking the shapes for the fold_train and fold_test\n",
    "fold_train.shape == (120, 4)\n",
    "fold_test.shape == (61, 4)\n",
    "\n",
    "## Double-checking the starting point and the ending point for both folds\n",
    "# assert (fold_train.index.start) == 0\n",
    "# assert (fold_train.index.stop) == 126\n",
    "# assert (fold_test.index.start) == 119 # 365 - 7 Jours prédiction sur 7 jours soit les 7 derniers jours non utilisés dans le training \n",
    "# assert (fold_test.index.stop) == 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c93079",
   "metadata": {},
   "source": [
    "### (2.3) 💻 🔢 Create (X, y) sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fd863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.522097Z",
     "start_time": "2022-12-01T09:52:42.518622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "print(\"##### INPUTS #####\")\n",
    "print(f'- INPUT_LENGTH = {INPUT_LENGTH} timesteps = {int(INPUT_LENGTH)} days = {int(INPUT_LENGTH/7)} week')\n",
    "print(f'- N_FEATURES = {N_FEATURES}')\n",
    "# Outputs\n",
    "print(\"##### OUTPUTS #####\")\n",
    "print(f'- OUTPUT_LENGTH = {OUTPUT_LENGTH} timesteps = {int(OUTPUT_LENGTH)} day(s)')\n",
    "print(f'- N_TARGETS = {N_TARGETS}')\n",
    "# Parameters\n",
    "print(\"##### PARAMETERS #####\")\n",
    "print(f'- HORIZON = {HORIZON} timesteps = {int(HORIZON)} day(s)')\n",
    "# Train\n",
    "print(\"##### TRAIN SET #####\")\n",
    "print(f\"- The training fold starts at index {fold_train.index.start} and stops at index {fold_train.index.stop}.\")\n",
    "# Test\n",
    "print(\"##### TEST SET #####\")\n",
    "print(f\"- The test fold starts at index {fold_test.index.start} and stops at index {fold_test.index.stop}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d002d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.526397Z",
     "start_time": "2022-12-01T09:52:42.523572Z"
    }
   },
   "outputs": [],
   "source": [
    "# New: Scanning  through a fold  \n",
    "STRIDE = 1 # sliding every  days, for subfolds\n",
    "print(f'STRIDE = {STRIDE} timesteps = {int(STRIDE)} day()')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b8c6e",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Extracting a <font color=\"#884dff\"><i>sequence</i></font>)** \n",
    "\n",
    "Code the function `get_Xi_yi` which extracts a <font color=\"#884dff\"><i>sequence</i></font> from a Time Series: it should take the following arguments:\n",
    "- `first_index`\n",
    "- `data` (your 2D-dataframe representing the Time Series)\n",
    "- `input_length`\n",
    "- `output_length`\n",
    "- `horizon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51d57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.531004Z",
     "start_time": "2022-12-01T09:52:42.527803Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Xi_yi(first_index: int, \n",
    "              fold: pd.DataFrame, \n",
    "              horizon: int,\n",
    "              input_length: int,\n",
    "              output_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    - extracts one sub-fold from a fold\n",
    "    - returns a pair (Xi, yi) with:\n",
    "        * len(Xi) = `input_length` and Xi starting at first_index\n",
    "        * len(yi) = `output_length`\n",
    "        * last_Xi and first_yi separated by the gap = horizon -1\n",
    "    '''\n",
    "\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "\n",
    "    Xi_start = first_index\n",
    "    Xi_last = Xi_start + input_length\n",
    "    yi_start = Xi_last + horizon - 1\n",
    "    yi_last = yi_start + output_length\n",
    "\n",
    "    Xi = fold[Xi_start:Xi_last]\n",
    "    yi = fold[yi_start:yi_last][TARGET]\n",
    "\n",
    "    return (Xi, yi)\n",
    "\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9628927",
   "metadata": {},
   "source": [
    "🧪 Run the following cell to test your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88413489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.537059Z",
     "start_time": "2022-12-01T09:52:42.532150Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing your function get_Xi_yi\n",
    "\n",
    "first_index = fold.index.start\n",
    "Xi, yi = get_Xi_yi(first_index=first_index,\n",
    "                   fold=fold,\n",
    "                   horizon=HORIZON,\n",
    "                   input_length=INPUT_LENGTH,\n",
    "                   output_length=OUTPUT_LENGTH)\n",
    "\n",
    "# assert (Xi.index.start == first_index)\n",
    "# assert (Xi.shape == (INPUT_LENGTH, 4))\n",
    "# assert (yi.index.stop == Xi.index.stop + HORIZON - 1 + OUTPUT_LENGTH)\n",
    "# assert (yi.shape == (OUTPUT_LENGTH, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346371a",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Creating <font color=\"#884dff\"><i>sequences</i></font>, scanning chronologically through a fold)** \n",
    "\n",
    "Code the function `get_X_y` to scan an entire fold and extract sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c36b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.543843Z",
     "start_time": "2022-12-01T09:52:42.538479Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_X_y(fold: pd.DataFrame,\n",
    "            horizon: int,\n",
    "            input_length: int,\n",
    "            output_length: int,\n",
    "            stride: int,\n",
    "            shuffle=True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    - Uses `data`, a 2D-array with axis=0 for timesteps, and axis=1 for (targets+covariates columns)\n",
    "    - Returns a Tuple (X,y) of two ndarrays :\n",
    "        * X.shape = (n_samples, input_length, n_covariates)\n",
    "        * y.shape =\n",
    "            (n_samples, output_length, n_targets) if all 3-dimensions are of size > 1\n",
    "            (n_samples, output_length) if n_targets == 1\n",
    "            (n_samples, n_targets) if output_length == 1\n",
    "            (n_samples, ) if both n_targets and lenghts == 1\n",
    "    - You can shuffle the pairs (Xi,yi) of your fold\n",
    "    \"\"\"\n",
    "\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Scanning the fold/data entirely with a certain stride\n",
    "    for i in range(0, len(fold), stride):\n",
    "        ## Extracting a sequence starting at index_i\n",
    "        Xi, yi = get_Xi_yi(first_index=i,\n",
    "                           fold=fold,\n",
    "                           horizon=horizon,\n",
    "                           input_length=input_length,\n",
    "                           output_length=output_length)\n",
    "        ## Exits loop as soon as we reach the end of the dataset\n",
    "        if len(yi) < output_length:\n",
    "            break\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = np.squeeze(y)\n",
    "\n",
    "    if shuffle:\n",
    "        idx = np.arange(len(X))\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f849f",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ Generate <font color=\"#884dff\"><i>sequences</i></font>** both in the <font color=blue>**train**</font> set and the <font color=\"#ff8005\">**test**</font> set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24b188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.721752Z",
     "start_time": "2022-12-01T09:52:42.545049Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(fold=fold_train,\n",
    "                           horizon=HORIZON,\n",
    "                           input_length=INPUT_LENGTH,\n",
    "                           output_length=OUTPUT_LENGTH,\n",
    "                           stride=STRIDE)\n",
    "X_test, y_test = get_X_y(fold=fold_test,\n",
    "                         horizon=HORIZON,\n",
    "                         input_length=INPUT_LENGTH,\n",
    "                         output_length=OUTPUT_LENGTH,\n",
    "                         stride=STRIDE)\n",
    "\n",
    "print(\"Shapes for the training set:\")\n",
    "print(f\"X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}\")\n",
    "\n",
    "print(\"Shapes for the test set:\")\n",
    "print(f\"X_test.shape = {X_test.shape}, y_test.shape = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e408f",
   "metadata": {},
   "source": [
    "> For X_train, the base is 365 days. Subfolds have a length of 7 days. The 1st subfold xi is the 1st 7 days, and the 1st yi is the 8th to 14th days = 7 days.\n",
    "There are 358 days left for other subfolds (because the 1st subfold xi takes 7 days), but as y has a length of 7 days, there are 351 days left to subfold for xi.\n",
    "--> 1 subfold + 351 next subfolds.\n",
    "\n",
    "> For X_test, the base is 163 days (156 days + 7 last days of X_train). Subfolds have a length of 7 days. The 1st subfold xi is the 1st 7 days, and the 1st yi is the 8th to 14th days = 7 days.\n",
    "There are 156 days left for other subfolds (because the 1st subfold xi takes 7 days), but as y has a length of 7 days, there are 149 days left to subfold for xi.\n",
    "--> 1 subfold + 150 next subfolds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ace41",
   "metadata": {},
   "source": [
    "🧪 Test that your shapes are correct. If not, go back to the function to debug it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1532a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.726845Z",
     "start_time": "2022-12-01T09:52:42.723019Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, INPUT_LENGTH, N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef379843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.731058Z",
     "start_time": "2022-12-01T09:52:42.728035Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa2eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T16:43:11.481793Z",
     "start_time": "2022-11-30T16:43:11.438361Z"
    }
   },
   "outputs": [],
   "source": [
    "## ASSERTS\n",
    "# assert(X_train.shape == (113, INPUT_LENGTH, N_FEATURES))\n",
    "# assert(y_train.shape == (113, OUTPUT_LENGTH))\n",
    "# assert(X_test.shape == (48, INPUT_LENGTH, N_FEATURES))\n",
    "# assert(y_test.shape == (48, OUTPUT_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091406c6",
   "metadata": {},
   "source": [
    "## (3) 💻 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4d2cf",
   "metadata": {},
   "source": [
    "### (3.1) 💻 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd363d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:46:38.798994Z",
     "start_time": "2022-12-01T10:46:38.792106Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f063310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:46:39.103439Z",
     "start_time": "2022-12-01T10:46:39.094666Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ead37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7b2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:46:38.956000Z",
     "start_time": "2022-12-01T10:46:38.949175Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46696f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:06:01.474590Z",
     "start_time": "2022-12-01T11:06:01.467530Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f88aae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:23.986989Z",
     "start_time": "2022-12-01T11:24:23.975714Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train):\n",
    "\n",
    "     # 1 - RNN architecture\n",
    "    # ======================    \n",
    "    model = models.Sequential()  \n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=80, activation='relu', input_shape=X_train[0].shape ,return_sequences=True))\n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=60, activation='relu',return_sequences=True))\n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=40, activation='relu',return_sequences=True))\n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=20, activation='relu',return_sequences=True))\n",
    "\n",
    "    # Predictive Dense Layer \n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    # 2 - Compiler\n",
    "    # ======================\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.0001)\n",
    "\n",
    "    #Le sparse_categorical_crossentrop permet de ne pas avoir à faire un OneHotEncoding de la target en 6 catégories\n",
    "    adam = optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338bca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grid search\n",
    "# KO - A retester\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# HP_NUM_UNITS = hp.HParam('units', hp.Discrete([20, 40, 60, 80, 100]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'rmsprop']))\n",
    "\n",
    "# METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_EPOCHS],\n",
    "#         metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "#     )\n",
    "\n",
    "# def init_model2(X_train, y_train, hparams):\n",
    "\n",
    "#      # 1 - RNN architecture\n",
    "#     # ======================    \n",
    "#     model = models.Sequential()  \n",
    "    \n",
    "# #    normalizer = Normalization()\n",
    "# #    normalizer.adapt(X_train)\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',input_shape=X_train[0].shape ,return_sequences=True))\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',return_sequences=True))\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',return_sequences=True))\n",
    "#     model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',return_sequences=True))\n",
    "#     model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "\n",
    "#     # Predictive Dense Layer \n",
    "#     model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    \n",
    "#     # 2 - Compiler\n",
    "#     # ======================\n",
    "#     #initial_learning_rate = 0.001\n",
    "#     #lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.0001)\n",
    "\n",
    "#     #Le sparse_categorical_crossentrop permet de ne pas avoir à faire un OneHotEncoding de la target en 6 catégories\n",
    "#     #adam = optimizers.Adam(learning_rate=lr_schedule)\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=hparams[HP_OPTIMIZER], metrics=[\"accuracy\"])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3dec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.359190Z",
     "start_time": "2022-12-01T11:24:24.134293Z"
    }
   },
   "outputs": [],
   "source": [
    "model = init_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c79aae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.368305Z",
     "start_time": "2022-12-01T11:24:24.360618Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58a701",
   "metadata": {},
   "source": [
    "🎁 **Training**: We can re-use the function `fit_model` from the last challenge to <font color=blue>train</font> the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7cc76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.555350Z",
     "start_time": "2022-12-01T11:24:24.550437Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def fit_model(model: tf.keras.Model, verbose=1) -> Tuple[tf.keras.Model, dict]:\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\",\n",
    "                       patience=5,\n",
    "                       mode=\"min\",\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.3,\n",
    "                        shuffle=False,\n",
    "                        batch_size=32,\n",
    "                        epochs=80,\n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aaef12",
   "metadata": {},
   "source": [
    "🎁 **Visualizing performance:** Feel free to use the `plot_history` function to visualize how your model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6b2d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.857534Z",
     "start_time": "2022-12-01T11:24:24.845280Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # --- LOSS: Sparse_categorical_crossentropy --- \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- METRICS: accuracy ---\n",
    "    \n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "    ax[1].set_title('accuracy')\n",
    "    ax[1].set_ylabel('accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a96891",
   "metadata": {},
   "source": [
    "💻 ❓ **Questions ❓ (Training and Evaluating the LSTM model)**\n",
    "\n",
    "Using your functions `init_model` and `fit_model`:\n",
    "1. **Initialize** your model\n",
    "2. <font color=blue>**Train**</font> it and observe the performances on the train set and the validation set\n",
    "3. <font color=orange>**Evaluate**</font> it on the test set\n",
    "\n",
    "_Feel free to apply regularization techniques in the architecture if the model overfits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed34b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:32.149324Z",
     "start_time": "2022-12-01T11:24:25.171175Z"
    },
    "scrolled": false,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 - Initialising the RNN model\n",
    "# ==================================== #\n",
    "model = init_model(X_train, y_train)\n",
    "#model.summary()\n",
    "\n",
    "# 2 - Training\n",
    "# ====================================\n",
    "model, history = fit_model(model, verbose=1)\n",
    "plot_history(history);\n",
    "\n",
    "# 3 - Evaluation\n",
    "# ====================================\n",
    "res = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(f\"The LSTM accuracy on the test set is equal to {round(res[1],2)}, (meaning the model is guessing the correct predictions {round(res[1]*100,2)}% of the time).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e75dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:32.553165Z",
     "start_time": "2022-12-01T11:24:32.150946Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1dbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:36:12.380070Z",
     "start_time": "2022-12-01T11:36:12.309587Z"
    }
   },
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test)[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead08e85",
   "metadata": {},
   "source": [
    "### (3.2) 🎁 Baseline with a horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ce810",
   "metadata": {},
   "source": [
    "👉 (*Reminder*) ***In Time Series, an \"intuitive\" baseline model is to repeat the last seen value as (a) prediction(s) for the future value(s)*** you want to forecast, as illustrated down below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38715e66",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/davydw/public-pictures/blob/main/last_seen_value_with_horizon.png?raw=true\" width = 600 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354117b",
   "metadata": {},
   "source": [
    "🎁 **The Last Seen Value Baseline Model** \n",
    "\n",
    "Let's go together through the function `baseline` which:\n",
    "- (_input_) takes a pair $(X, y)$ \n",
    "- (_output_) computes the accuracy of the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12040fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.775583Z",
     "start_time": "2022-11-30T14:39:34.772023Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # import library\n",
    "\n",
    "def baseline(df):\n",
    "    df['ATMO_baseline'] = df['ATMO'].shift(periods=8,axis=0) #creation of y_pred by shifting target of 7 days\n",
    "    y_baseline = df['ATMO_baseline'][8:] #take off the 7 first values to drop nan\n",
    "    y_true = df['ATMO'][8:] #take off the 7 first values to drop nan\n",
    "    accuracy = accuracy_score(y_true, y_baseline) # use accuracy modul from sklearn\n",
    "    df = df.drop(columns = ['ATMO_baseline'])\n",
    "\n",
    "    return df, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542127c5",
   "metadata": {},
   "source": [
    "🕵🏻‍♀️ What is the performance of the \"last seen value baseline model\" on the <font color=orange>**test**</font> set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c5763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.780798Z",
     "start_time": "2022-11-30T14:39:34.777313Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 - Evaluation of the baseline model\n",
    "# ====================================\n",
    "df, accuracy_baseline = baseline(df)\n",
    "\n",
    "print(f\"- The baseline accuracy_baseline on the test set is equal to {round(accuracy_baseline,2)}\")\n",
    "\n",
    "# 4 - Comparison with the LSTM model\n",
    "# ====================================\n",
    "print(f\"- The LSTM accuracy_baseline on the test set is equal to {round(res[1],2)}, (meaning the model is guessing the correct predictions {round(res[1]*100,2)}% of the time).\")\n",
    "print(f\"👉 Improvement/decrease of the LSTM model over the baseline (on this fold for the test set) = : {round(((res[1]-accuracy_baseline)/accuracy_baseline)*100,2)} % 👈\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ccf45c",
   "metadata": {},
   "source": [
    "<u><b><i>Warnings:</i></b></u>\n",
    "\n",
    "* <font color=red>***The more data points in the future we try to predict, the lower your accuracy will be!***</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1254d01",
   "metadata": {},
   "source": [
    "### (3.3) 💻 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d14926",
   "metadata": {},
   "source": [
    "ℹ️ Reminders of the global variables in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35955631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.788288Z",
     "start_time": "2022-11-30T14:39:34.782170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folds\n",
    "print('##### FOLDS ##### ')\n",
    "print(f'- FOLD_LENGTH = {FOLD_LENGTH} timesteps = {1} year x {365} days x {1} record per day + 156 days of test')\n",
    "print(f'- FOLD_STRIDE = {FOLD_STRIDE} timesteps = {(365/4)} days x {1} record per day(s) = sliding each trimester')\n",
    "\n",
    "# Chronological Train Test Split\n",
    "print('##### TRAIN TEST SPLIT #####')\n",
    "print(f'- TRAIN_TEST_RATIO = {TRAIN_TEST_RATIO}')\n",
    "#print(f'- N_TRAIN = {N_TRAIN}')\n",
    "#print(f'- N_TEST = {N_TEST}')\n",
    "\n",
    "# Inputs\n",
    "print('##### INPUTS #####')\n",
    "print(f'- INPUT_LENGTH = {INPUT_LENGTH} timesteps = {int(INPUT_LENGTH)} days x {1} record(s) per day = {int(INPUT_LENGTH/7)} week(s)')\n",
    "print(f'- N_FEATURES = {N_FEATURES}') \n",
    "\n",
    "# Outputs\n",
    "print('##### OUTPUTS #####')\n",
    "print(f'- OUTPUT_LENGTH = {OUTPUT_LENGTH} timesteps = {int(OUTPUT_LENGTH)} day(s) x {1} record(s) per day')\n",
    "print(f\"- Trying to predict:{TARGET}\")\n",
    "print(f'- N_TARGETS = {N_TARGETS}') \n",
    "\n",
    "# Parameters\n",
    "print('##### PARAMETERS #####')\n",
    "print(f'- HORIZON = {HORIZON} timesteps = {int(HORIZON)} day(s) x {8} record(s) per day')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2e691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.797101Z",
     "start_time": "2022-11-30T14:39:34.791318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remember how many folds do we have ?\n",
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "print(f\"WARNING, we have {len(folds)} FOLDS, it may take a long time to run...!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafe484",
   "metadata": {},
   "source": [
    "🎁 **Cross-validating the LSTM and the baseline** \n",
    "\n",
    "_Let's go together through the following code_ 👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442bac8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:59.711962Z",
     "start_time": "2022-11-30T14:39:45.772891Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_accuracy_baseline_model = []\n",
    "list_of_accuracy_recurrent_model = []\n",
    "    \n",
    "# 1 - Creating FOLDS\n",
    "# =======================================================\n",
    "    \n",
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "    \n",
    "for fold_id, fold in enumerate(folds):    \n",
    "    \n",
    "    # 2 - CHRONOLOGICAL TRAIN TEST SPLIT of the current FOLD\n",
    "    # =======================================================    \n",
    "    \n",
    "    (fold_train, fold_test) = train_test_split(fold = fold, \n",
    "                                               train_test_ratio = TRAIN_TEST_RATIO, \n",
    "                                               input_length = INPUT_LENGTH, \n",
    "                                               horizon = HORIZON) \n",
    "    \n",
    "    # 3 - Scanninng fold_train and fold_test for SEQUENCES \n",
    "    # =======================================================       \n",
    "    \n",
    "    X_train, y_train = get_X_y(fold = fold_train, \n",
    "                               horizon = HORIZON, \n",
    "                               input_length = INPUT_LENGTH, \n",
    "                               output_length = OUTPUT_LENGTH, \n",
    "                               stride = STRIDE)\n",
    "    \n",
    "    X_test, y_test = get_X_y(fold_test, \n",
    "                             horizon = HORIZON, \n",
    "                             input_length = INPUT_LENGTH, \n",
    "                             output_length = OUTPUT_LENGTH,\n",
    "                             stride = STRIDE)\n",
    "    \n",
    "    # 4.1 - Baseline Model\n",
    "    # =======================================================\n",
    "    df, accuracy_baseline = baseline(df)\n",
    "        \n",
    "    list_of_accuracy_baseline_model.append(accuracy_baseline)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(f\"Accuracy baseline fold n°{fold_id} = {round(accuracy_baseline, 2)}\")        \n",
    "    \n",
    "    \n",
    "    # 4.2 - LSTM Model\n",
    "    # =======================================================\n",
    "    \n",
    "    # Initializing the LSTM Model\n",
    "    model = init_model(X_train, y_train)\n",
    "    \n",
    "    # Training\n",
    "    model, history = fit_model(model, verbose=0)\n",
    "    \n",
    "    # Evaluation\n",
    "    res = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    accuracy_lstm = res[1]\n",
    "    \n",
    "    list_of_accuracy_recurrent_model.append(accuracy_lstm)\n",
    "    \n",
    "    print(f\"Accuracy LSTM fold n°{fold_id} = {round(accuracy_lstm, 2)}\")\n",
    "    \n",
    "    # 4.3 - Comparison LSTM vs Baseline for the current fold\n",
    "    # =======================================================\n",
    "    print(f\"🏋🏽‍♂️ Improvement/Decrease vs. Baseline: {round(((accuracy_lstm-accuracy_baseline)/accuracy_baseline)*100,2)} % \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeeec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_accuracy_recurrent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6d883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T13:17:09.665867Z",
     "start_time": "2022-11-30T13:17:09.125956Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_accuracy_baseline = np.mean(list_of_accuracy_baseline_model)\n",
    "cv_accuracy_lstm = np.mean(list_of_accuracy_recurrent_model)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(f\"Average accuracy baseline = {round(cv_accuracy_baseline, 2)}\")    \n",
    "print(f\"Average accuracy LSTM = {round(cv_accuracy_lstm, 2)}\")    \n",
    "print(f\"🏋🏽‍♂️ Improvement/Decrease vs. Baseline: {round(((cv_accuracy_lstm-cv_accuracy_baseline)/cv_accuracy_baseline)*100,2)} % \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374c5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb9ebc3f",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f354ba2",
   "metadata": {},
   "source": [
    "## (0) Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313147b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.431318Z",
     "start_time": "2022-12-01T09:52:38.970273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# Checking data types\n",
    "from typing import Dict, List, Tuple, Sequence\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d902a",
   "metadata": {},
   "source": [
    "## (1) 📚 The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a136e",
   "metadata": {},
   "source": [
    "### (1.1) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0523b",
   "metadata": {},
   "source": [
    "💾 Load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924e9b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.458779Z",
     "start_time": "2022-12-01T09:52:42.447651Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pollution/inputs/Xy_PA75016.csv',index_col='Date_time')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab7593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.472350Z",
     "start_time": "2022-12-01T09:52:42.459953Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd7943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:41:26.261342Z",
     "start_time": "2022-12-01T10:41:26.250185Z"
    }
   },
   "outputs": [],
   "source": [
    "df['ATMO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9bd9d",
   "metadata": {},
   "source": [
    "👆 *(Reminders*) This weather dataset is a ***single Time Series*** represented as a DataFrame, i.e. a **2D-array**.\n",
    "- `df.shape = (n_timesteps, n_features)`\n",
    "    - `n_timesteps` $= 1775$k rows  (_~5 years of weather data, from 2018 to 2022 with 1 record every day (mean from hourly records_)\n",
    "    - `n_features` $= 4$ features composed of:\n",
    "        - $1$ <font color=green>**target**</font> (we will use the past values of the temperature as a feature)\n",
    "        - $4$ <font color=orange>**past covariates**</font> (= features which past values are known)\n",
    "        - $0$ <font color=blue>**future covariates**</font> (= features which future values are known, e.g. public holidays)\n",
    "    \n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/time-series-covariates.png?raw=true'>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf26a04",
   "metadata": {},
   "source": [
    "### (1.2) 🌅 The big picture about dealing with Time Series *(reminder)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd353731",
   "metadata": {},
   "source": [
    "1️⃣ <b>[FOLDS] <u>Cross-Validation in Time Series  </u></b>\n",
    "\n",
    "Starting from this single Time Series:\n",
    "- We will create <font color=\"#c91ac9\">**FOLDS**</font>\n",
    "- <font color=blue>**Train**</font>/<font color=\"#ff8005\">**Evaluate**</font> our LSTM  <font color=\"#c91ac9\">**on each of these different FOLDS**</font> to conclude about <b><u>the robustness of the model</u><b>.\n",
    "    \n",
    "_It is very common to create hundreds of folds in Time Series forecasting, in order to cover all types of external conditions: crash market periods, bull markets, atone markets, etc..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807dafa",
   "metadata": {},
   "source": [
    "2️⃣ <b>[TRAIN-TEST SPLIT] <u>Holdout method</u></b>\n",
    "\n",
    "For each <font color=\"#c91ac9\">**FOLD**</font>, we will do a <font color=blue>**TRAIN**</font>-<font color=\"#ff8005\">**TEST**</font> SPLIT to:\n",
    "* <font color=blue>**fit**</font> the model on the <font color=blue>**train**</font> set \n",
    "* <font color=\"#ff8005\">**evaluate**</font> it on the <font color=\"#ff8005\">**test**</font> set\n",
    "\n",
    "_Always split the train set **chronologically** before the test set!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfa9f9",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "👇 The first two steps can be summarized in the following image (here, we illustrated a 4-fold temporal cross-validation):\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/time_series_cross_validation.png\" alt=\"Time Series Cross Validation\" width=\"800\" height=\"400\">\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458652b",
   "metadata": {},
   "source": [
    "3️⃣ <b>[SEQUENCES] <u>Sampling/Extracting sequences</u></b>\n",
    "\n",
    "\n",
    "After splitting each fold into a <font color=\"blue\">train</font> set and a <font color=\"#ff8005\">test</font> set, it is time to:\n",
    "- 🏋 sample lots of <font color=\"#884dff\"><i>sequences</i></font> $\\color{blue}{(X_i, y_i)}$ on which the model will be <font color=\"blue\">trained</font>\n",
    "- 👩🏻‍🏫 sample lots of <font color=\"#884dff\"><i>sequences</i></font> $\\color{#ff8005}{(X_i, y_i)}$ on which the model will be <font color=\"#ff8005\">evaluated</font>\n",
    "\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> \n",
    "\n",
    "👉 All these <font color=\"#884dff\"><i>sequences</i></font> in the <font color=\"blue\">train</font> set and the <font color=\"#ff8005\">test</font> set will have a common shape `(input_length, n_features)` $ = (14\\times8,19) = (112,19)$.\n",
    "\n",
    "👉 Each <font color=\"#884dff\"><i>sequence</i></font> has a target, the shape of which will be `(output_length, n_targets)` $ = (7\\times8, 1) = (56, 1)$.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/shapes_for_input_sequence_and_ouput_sequence.png\" alt=\"3d arrays time series\" width=\"1200\" height=\"800\"> \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9ba66",
   "metadata": {},
   "source": [
    "> 🔥 Open this [**infograph**](https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/big_picture_temporal_data_handling.png)  side-by-side with the notebook for a visual summary! 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c6911",
   "metadata": {},
   "source": [
    "## (2) Adapting the functions from the _\"Predict Temperature\"_ challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d577f0",
   "metadata": {},
   "source": [
    "### (2.0) Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c295c0d",
   "metadata": {},
   "source": [
    "🌐 Let's define some ***global variables*** that we will use for our tests everywhere in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10629e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.476727Z",
     "start_time": "2022-12-01T09:52:42.473608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folds\n",
    "FOLD_LENGTH = 521      # dont 365J Train +  156J Test\n",
    "FOLD_STRIDE = int(209) # sliding each semester - décalage de 209J pour obtenir 7 folds\n",
    "\n",
    "# Temporal Train-Test split\n",
    "TRAIN_TEST_RATIO = 0.7 #70% de train et 30% de test par fold\n",
    "#N_TRAIN = 365 # number_of_sequences_train for each fold_train\n",
    "#N_TEST = 156 # number_of_sequences_test for each fold_test\n",
    "\n",
    "# Inputs\n",
    "N_FEATURES = 4  # 3 polluants + l'ATMO index\n",
    "INPUT_LENGTH = 7 # - Records 1 week ~ 7 days. One week is quite common for air quality  \n",
    "\n",
    "# Outputs\n",
    "TARGET = ['ATMO']\n",
    "TARGET_COLUMN_IDX = 3 # Corresponds to the third column of the df\n",
    "N_TARGETS = 1\n",
    "OUTPUT_LENGTH = N_TARGETS*7 # Predicting one target, the ATMO index for 7 days\n",
    "                              \n",
    "\n",
    "# Additional parameters\n",
    "HORIZON = 1 # - You want to predict this point HORIZON = 1 day after the last known value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216bc19",
   "metadata": {},
   "source": [
    "### (2.1)  🗂 <font color=\"#c91ac9\">FOLDS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa54533",
   "metadata": {},
   "source": [
    "🎁 **`get_folds`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5db7da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.483227Z",
     "start_time": "2022-12-01T09:52:42.479932Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_folds(df: pd.DataFrame, \n",
    "              fold_length: int,\n",
    "              fold_stride: int) -> List[pd.DataFrame]:\n",
    "    '''\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "    \n",
    "    Returns a list of folds, each as a DataFrame\n",
    "    '''\n",
    "\n",
    "    folds = []\n",
    "    for idx in range(0, len(df), fold_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (idx + fold_length) > len(df):\n",
    "            break\n",
    "        fold = df.iloc[idx:idx + fold_length, :]\n",
    "        folds.append(fold)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd058903",
   "metadata": {},
   "source": [
    "👉 Let's generate these <font color=\"#c91ac9\">**FOLDS**</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8008d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.489237Z",
     "start_time": "2022-12-01T09:52:42.484283Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "\n",
    "print(f'The function generated {len(folds)} folds.')\n",
    "print(f'Each fold has a shape equal to {folds[0].shape}.')\n",
    "print(f'The last fold has a shape equal to {folds[-1].shape}.')\n",
    "np.array(folds).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccf7e1",
   "metadata": {},
   "source": [
    "7 Folds\n",
    "\n",
    "521 Observations (fold_length)\n",
    "\n",
    "4 features (3 pollutants + 1 target )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e98b7",
   "metadata": {},
   "source": [
    "🧪 Make sure that the following <font color=green>***assert***</font> doesn't return anything (which means the assertion is correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d5709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.492375Z",
     "start_time": "2022-12-01T09:52:42.490399Z"
    }
   },
   "outputs": [],
   "source": [
    "#assert(folds[0].shape == (180, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5673a1c",
   "metadata": {},
   "source": [
    "☝️ This amount of <font color=\"#c91ac9\">**FOLDS**</font> should be enough to cross-validate our model correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfbd338",
   "metadata": {},
   "source": [
    "### (2.2) ✂️  Temporal <font color=blue>Train</font>/<font color=\"#ff8005\">Test</font> Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62844ca",
   "metadata": {},
   "source": [
    "👩🏻‍🏫 Let's <font color=\"#c91ac9\">focus on one fold</font> for the moment, the first one for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccfbdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.500914Z",
     "start_time": "2022-12-01T09:52:42.493491Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = folds[-1]\n",
    "fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21efc5ee",
   "metadata": {},
   "source": [
    "⌚️ We want to ***split this <font color=\"#c91ac9\">fold</font> chronologically*** into a <font color=blue>***fold_train***</font> and a <font color=\"#ff8005\">***fold_test***</font>.\n",
    "\n",
    "*Each of these fold_train and fold_test will contain all the data we need to be able to sample many pairs `(Xi, yi)` in a next step!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac8ed7",
   "metadata": {},
   "source": [
    "#### (2.2.1) 🧑🏻‍🏫 The complexity introduced by the <font color=green>gap</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db24426",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>⏸ Let's take a <i>quick break</i> from this weather dataset to understand what is a temporal gap.</summary>\n",
    "\n",
    "<hr>\n",
    "\n",
    "🤑 Put yourself in the shoes of a quantitative trader at timesteps $\\color{blue}{1}, \\color{blue}{2}, \\color{blue}{3}, ..., \\color{blue}{10}$.\n",
    "\n",
    "Let's say you are in the <font color=blue>training</font> phase, and you want to stop your training after day `10`:\n",
    "- You have to wait until day `10` to know the real value $y_{10}$, and compare it with the predicted value $\\hat{y}_{10}$ to train the model.\n",
    " \n",
    "Here are the <font color=blue>assumptions about your model</font>:\n",
    "- It is trained on <font color=\"#884dff\"><i>sequences</i></font> with `INPUT_LENGTH = 3`\n",
    "- The goal is to predict `OUTPUT_LENGTH = 1` point in the future\n",
    "- You want to predict this point `HORIZON = 4` days after the last known value.\n",
    "\n",
    "✅ Imagine that your model was trained and put into production\n",
    "\n",
    "❓ <u>On which day can you evaluate the live performance of the model for the first time</u> ❓\n",
    "\n",
    "* You are at day `10`. Hence, the first prediction you can make is for day `10` + `HORIZON` = `14`\n",
    "* You will have to wait until day `14` to see how good was your prediction!\n",
    "    * `y_test_first` = day `14`\n",
    "* You sit IDLE for <font color=green>3</font> days $(11, 12, 13)$\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ba07c",
   "metadata": {},
   "source": [
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/train_test_split_with_horizon.jpg?raw=true\" height=500 width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a541d",
   "metadata": {},
   "source": [
    "👉 The <font color=green>gap</font> between the <font color=blue>train</font> and the <font color=orange>test</font> set should be equal to `GAP = HORIZON - 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885f466",
   "metadata": {},
   "source": [
    "#### (2.2.2) 💻 Adapting the  `train_test_split` function accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ae61f",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Temporal <font color=blue>Train</font>/<font color=orange>Test</font> split)** \n",
    "\n",
    "Code the function `train_test_split` down below which:\n",
    "- <i>(inputs)</i> given \n",
    "    - a `fold` (like above), \n",
    "    - a `train_test_ratio` (e.g 0.8) \n",
    "    - an `input_length` (fixed)\n",
    "    - 🆕 a `horizon` (fixed)\n",
    "- <i>(output)</i> returns a tuple (`fold_train`, `fold_test`) of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19bae1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.506199Z",
     "start_time": "2022-12-01T09:52:42.502534Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(fold: pd.DataFrame, \n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int, \n",
    "                     horizon: int) -> Tuple[pd.DataFrame]:\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe (fold_train, fold_test)\n",
    "    from which one can sample (X,y) sequences.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))   \n",
    "    '''\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "\n",
    "    # TRAIN SET\n",
    "    # ======================\n",
    "    last_train_idx = round(train_test_ratio * len(fold))\n",
    "    fold_train = fold.iloc[0:last_train_idx, :]\n",
    "\n",
    "    # TEST SET\n",
    "    # ======================\n",
    "    first_test_idx = last_train_idx - input_length\n",
    "    fold_test = fold.iloc[first_test_idx:, :]\n",
    "\n",
    "    return (fold_train, fold_test)\n",
    "\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42648461",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Temporal <font color=blue>Train</font>/<font color=orange>Test</font> split for <font color=\"#c91ac9\">one fold </font>)** \n",
    "\n",
    "Split the <font color=\"#c91ac9\">fold #0</font>.\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary><i>Reminders</i></summary>\n",
    "\n",
    "*As a reminder, in  section `(2.0) Global Variables`, we defined*:\n",
    "- *`TRAIN_TEST_RATIO` = 66%* \n",
    "- *`INPUT_LENGTH` = 2 weeks = 112 time steps for each `Xi`, which is quite common in weather forecasting*\n",
    "- *`HORIZON` = 1 day = 8 time steps*\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ce0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.510156Z",
     "start_time": "2022-12-01T09:52:42.507546Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "(fold_train, fold_test) = train_test_split(fold, \n",
    "                                           TRAIN_TEST_RATIO,\n",
    "                                           INPUT_LENGTH, \n",
    "                                           HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef4c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.513833Z",
     "start_time": "2022-12-01T09:52:42.511215Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_train.shape, fold_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3c0f5",
   "metadata": {},
   "source": [
    "🧪 Check that your shapes and your starting/ending points are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7496134",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_train.index.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04fe373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.517539Z",
     "start_time": "2022-12-01T09:52:42.514903Z"
    }
   },
   "outputs": [],
   "source": [
    "## Double-checking the shapes for the fold_train and fold_test\n",
    "fold_train.shape == (120, 4)\n",
    "fold_test.shape == (61, 4)\n",
    "\n",
    "## Double-checking the starting point and the ending point for both folds\n",
    "# assert (fold_train.index.start) == 0\n",
    "# assert (fold_train.index.stop) == 126\n",
    "# assert (fold_test.index.start) == 119 # 365 - 7 Jours prédiction sur 7 jours soit les 7 derniers jours non utilisés dans le training \n",
    "# assert (fold_test.index.stop) == 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace234af",
   "metadata": {},
   "source": [
    "### (2.3) 💻 🔢 Create (X, y) sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e39892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.522097Z",
     "start_time": "2022-12-01T09:52:42.518622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "print(\"##### INPUTS #####\")\n",
    "print(f'- INPUT_LENGTH = {INPUT_LENGTH} timesteps = {int(INPUT_LENGTH)} days = {int(INPUT_LENGTH/7)} week')\n",
    "print(f'- N_FEATURES = {N_FEATURES}')\n",
    "# Outputs\n",
    "print(\"##### OUTPUTS #####\")\n",
    "print(f'- OUTPUT_LENGTH = {OUTPUT_LENGTH} timesteps = {int(OUTPUT_LENGTH)} day(s)')\n",
    "print(f'- N_TARGETS = {N_TARGETS}')\n",
    "# Parameters\n",
    "print(\"##### PARAMETERS #####\")\n",
    "print(f'- HORIZON = {HORIZON} timesteps = {int(HORIZON)} day(s)')\n",
    "# Train\n",
    "print(\"##### TRAIN SET #####\")\n",
    "print(f\"- The training fold starts at index {fold_train.index.start} and stops at index {fold_train.index.stop}.\")\n",
    "# Test\n",
    "print(\"##### TEST SET #####\")\n",
    "print(f\"- The test fold starts at index {fold_test.index.start} and stops at index {fold_test.index.stop}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fe35d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.526397Z",
     "start_time": "2022-12-01T09:52:42.523572Z"
    }
   },
   "outputs": [],
   "source": [
    "# New: Scanning  through a fold  \n",
    "STRIDE = 1 # sliding every  days, for subfolds\n",
    "print(f'STRIDE = {STRIDE} timesteps = {int(STRIDE)} day()')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad901fa",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Extracting a <font color=\"#884dff\"><i>sequence</i></font>)** \n",
    "\n",
    "Code the function `get_Xi_yi` which extracts a <font color=\"#884dff\"><i>sequence</i></font> from a Time Series: it should take the following arguments:\n",
    "- `first_index`\n",
    "- `data` (your 2D-dataframe representing the Time Series)\n",
    "- `input_length`\n",
    "- `output_length`\n",
    "- `horizon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361867e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.531004Z",
     "start_time": "2022-12-01T09:52:42.527803Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Xi_yi(first_index: int, \n",
    "              fold: pd.DataFrame, \n",
    "              horizon: int,\n",
    "              input_length: int,\n",
    "              output_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    - extracts one sub-fold from a fold\n",
    "    - returns a pair (Xi, yi) with:\n",
    "        * len(Xi) = `input_length` and Xi starting at first_index\n",
    "        * len(yi) = `output_length`\n",
    "        * last_Xi and first_yi separated by the gap = horizon -1\n",
    "    '''\n",
    "\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "\n",
    "    Xi_start = first_index\n",
    "    Xi_last = Xi_start + input_length\n",
    "    yi_start = Xi_last + horizon - 1\n",
    "    yi_last = yi_start + output_length\n",
    "\n",
    "    Xi = fold[Xi_start:Xi_last]\n",
    "    yi = fold[yi_start:yi_last][TARGET]\n",
    "\n",
    "    return (Xi, yi)\n",
    "\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d85bb",
   "metadata": {},
   "source": [
    "🧪 Run the following cell to test your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfd33a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.537059Z",
     "start_time": "2022-12-01T09:52:42.532150Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing your function get_Xi_yi\n",
    "\n",
    "first_index = fold.index.start\n",
    "Xi, yi = get_Xi_yi(first_index=first_index,\n",
    "                   fold=fold,\n",
    "                   horizon=HORIZON,\n",
    "                   input_length=INPUT_LENGTH,\n",
    "                   output_length=OUTPUT_LENGTH)\n",
    "\n",
    "# assert (Xi.index.start == first_index)\n",
    "# assert (Xi.shape == (INPUT_LENGTH, 4))\n",
    "# assert (yi.index.stop == Xi.index.stop + HORIZON - 1 + OUTPUT_LENGTH)\n",
    "# assert (yi.shape == (OUTPUT_LENGTH, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680ac6a",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ (Creating <font color=\"#884dff\"><i>sequences</i></font>, scanning chronologically through a fold)** \n",
    "\n",
    "Code the function `get_X_y` to scan an entire fold and extract sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed83f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.543843Z",
     "start_time": "2022-12-01T09:52:42.538479Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_X_y(fold: pd.DataFrame,\n",
    "            horizon: int,\n",
    "            input_length: int,\n",
    "            output_length: int,\n",
    "            stride: int,\n",
    "            shuffle=True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    - Uses `data`, a 2D-array with axis=0 for timesteps, and axis=1 for (targets+covariates columns)\n",
    "    - Returns a Tuple (X,y) of two ndarrays :\n",
    "        * X.shape = (n_samples, input_length, n_covariates)\n",
    "        * y.shape =\n",
    "            (n_samples, output_length, n_targets) if all 3-dimensions are of size > 1\n",
    "            (n_samples, output_length) if n_targets == 1\n",
    "            (n_samples, n_targets) if output_length == 1\n",
    "            (n_samples, ) if both n_targets and lenghts == 1\n",
    "    - You can shuffle the pairs (Xi,yi) of your fold\n",
    "    \"\"\"\n",
    "\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Scanning the fold/data entirely with a certain stride\n",
    "    for i in range(0, len(fold), stride):\n",
    "        ## Extracting a sequence starting at index_i\n",
    "        Xi, yi = get_Xi_yi(first_index=i,\n",
    "                           fold=fold,\n",
    "                           horizon=horizon,\n",
    "                           input_length=input_length,\n",
    "                           output_length=output_length)\n",
    "        ## Exits loop as soon as we reach the end of the dataset\n",
    "        if len(yi) < output_length:\n",
    "            break\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = np.squeeze(y)\n",
    "\n",
    "    if shuffle:\n",
    "        idx = np.arange(len(X))\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17144e",
   "metadata": {},
   "source": [
    "💻 ❓ **Question ❓ Generate <font color=\"#884dff\"><i>sequences</i></font>** both in the <font color=blue>**train**</font> set and the <font color=\"#ff8005\">**test**</font> set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3383c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.721752Z",
     "start_time": "2022-12-01T09:52:42.545049Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(fold=fold_train,\n",
    "                           horizon=HORIZON,\n",
    "                           input_length=INPUT_LENGTH,\n",
    "                           output_length=OUTPUT_LENGTH,\n",
    "                           stride=STRIDE)\n",
    "X_test, y_test = get_X_y(fold=fold_test,\n",
    "                         horizon=HORIZON,\n",
    "                         input_length=INPUT_LENGTH,\n",
    "                         output_length=OUTPUT_LENGTH,\n",
    "                         stride=STRIDE)\n",
    "\n",
    "print(\"Shapes for the training set:\")\n",
    "print(f\"X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}\")\n",
    "\n",
    "print(\"Shapes for the test set:\")\n",
    "print(f\"X_test.shape = {X_test.shape}, y_test.shape = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353ecdf",
   "metadata": {},
   "source": [
    "> For X_train, the base is 365 days. Subfolds have a length of 7 days. The 1st subfold xi is the 1st 7 days, and the 1st yi is the 8th to 14th days = 7 days.\n",
    "There are 358 days left for other subfolds (because the 1st subfold xi takes 7 days), but as y has a length of 7 days, there are 351 days left to subfold for xi.\n",
    "--> 1 subfold + 351 next subfolds.\n",
    "\n",
    "> For X_test, the base is 163 days (156 days + 7 last days of X_train). Subfolds have a length of 7 days. The 1st subfold xi is the 1st 7 days, and the 1st yi is the 8th to 14th days = 7 days.\n",
    "There are 156 days left for other subfolds (because the 1st subfold xi takes 7 days), but as y has a length of 7 days, there are 149 days left to subfold for xi.\n",
    "--> 1 subfold + 150 next subfolds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597576d",
   "metadata": {},
   "source": [
    "🧪 Test that your shapes are correct. If not, go back to the function to debug it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f134fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.726845Z",
     "start_time": "2022-12-01T09:52:42.723019Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, INPUT_LENGTH, N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40d48e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T09:52:42.731058Z",
     "start_time": "2022-12-01T09:52:42.728035Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36718eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f5b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T16:43:11.481793Z",
     "start_time": "2022-11-30T16:43:11.438361Z"
    }
   },
   "outputs": [],
   "source": [
    "## ASSERTS\n",
    "# assert(X_train.shape == (113, INPUT_LENGTH, N_FEATURES))\n",
    "# assert(y_train.shape == (113, OUTPUT_LENGTH))\n",
    "# assert(X_test.shape == (48, INPUT_LENGTH, N_FEATURES))\n",
    "# assert(y_test.shape == (48, OUTPUT_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a90942",
   "metadata": {},
   "source": [
    "## (3) 💻 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aef220",
   "metadata": {},
   "source": [
    "### (3.1) 💻 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14f604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:46:38.798994Z",
     "start_time": "2022-12-01T10:46:38.792106Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3afb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:46:39.103439Z",
     "start_time": "2022-12-01T10:46:39.094666Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc833de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:46:38.956000Z",
     "start_time": "2022-12-01T10:46:38.949175Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49997afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:06:01.474590Z",
     "start_time": "2022-12-01T11:06:01.467530Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964613ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:23.986989Z",
     "start_time": "2022-12-01T11:24:23.975714Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train):\n",
    "\n",
    "     # 1 - RNN architecture\n",
    "    # ======================    \n",
    "    model = models.Sequential()  \n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=80, activation='relu', input_shape=X_train[0].shape ,return_sequences=True))\n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=60, activation='relu',return_sequences=True))\n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=40, activation='relu',return_sequences=True))\n",
    "    \n",
    "    # Recurrent Layer\n",
    "    model.add(layers.LSTM(units=20, activation='relu',return_sequences=True))\n",
    "\n",
    "    # Predictive Dense Layer \n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    # 2 - Compiler\n",
    "    # ======================\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.0001)\n",
    "\n",
    "    #Le sparse_categorical_crossentrop permet de ne pas avoir à faire un OneHotEncoding de la target en 6 catégories\n",
    "    adam = optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grid search\n",
    "# KO - A retester\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# HP_NUM_UNITS = hp.HParam('units', hp.Discrete([20, 40, 60, 80, 100]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'rmsprop']))\n",
    "\n",
    "# METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_EPOCHS],\n",
    "#         metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "#     )\n",
    "\n",
    "# def init_model2(X_train, y_train, hparams):\n",
    "\n",
    "#      # 1 - RNN architecture\n",
    "#     # ======================    \n",
    "#     model = models.Sequential()  \n",
    "    \n",
    "# #    normalizer = Normalization()\n",
    "# #    normalizer.adapt(X_train)\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',input_shape=X_train[0].shape ,return_sequences=True))\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',return_sequences=True))\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',return_sequences=True))\n",
    "#     model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "    \n",
    "#     # Recurrent Layer\n",
    "#     model.add(layers.LSTM(hparams[HP_NUM_UNITS], activation='relu',return_sequences=True))\n",
    "#     model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "\n",
    "#     # Predictive Dense Layer \n",
    "#     model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    \n",
    "#     # 2 - Compiler\n",
    "#     # ======================\n",
    "#     #initial_learning_rate = 0.001\n",
    "#     #lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.0001)\n",
    "\n",
    "#     #Le sparse_categorical_crossentrop permet de ne pas avoir à faire un OneHotEncoding de la target en 6 catégories\n",
    "#     #adam = optimizers.Adam(learning_rate=lr_schedule)\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=hparams[HP_OPTIMIZER], metrics=[\"accuracy\"])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1fae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.359190Z",
     "start_time": "2022-12-01T11:24:24.134293Z"
    }
   },
   "outputs": [],
   "source": [
    "model = init_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb559f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.368305Z",
     "start_time": "2022-12-01T11:24:24.360618Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89abbc4",
   "metadata": {},
   "source": [
    "🎁 **Training**: We can re-use the function `fit_model` from the last challenge to <font color=blue>train</font> the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a48fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.555350Z",
     "start_time": "2022-12-01T11:24:24.550437Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def fit_model(model: tf.keras.Model, verbose=1) -> Tuple[tf.keras.Model, dict]:\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\",\n",
    "                       patience=5,\n",
    "                       mode=\"min\",\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.3,\n",
    "                        shuffle=False,\n",
    "                        batch_size=32,\n",
    "                        epochs=80,\n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553665b",
   "metadata": {},
   "source": [
    "🎁 **Visualizing performance:** Feel free to use the `plot_history` function to visualize how your model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9baca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:24.857534Z",
     "start_time": "2022-12-01T11:24:24.845280Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # --- LOSS: Sparse_categorical_crossentropy --- \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- METRICS: accuracy ---\n",
    "    \n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "    ax[1].set_title('accuracy')\n",
    "    ax[1].set_ylabel('accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4872b8",
   "metadata": {},
   "source": [
    "💻 ❓ **Questions ❓ (Training and Evaluating the LSTM model)**\n",
    "\n",
    "Using your functions `init_model` and `fit_model`:\n",
    "1. **Initialize** your model\n",
    "2. <font color=blue>**Train**</font> it and observe the performances on the train set and the validation set\n",
    "3. <font color=orange>**Evaluate**</font> it on the test set\n",
    "\n",
    "_Feel free to apply regularization techniques in the architecture if the model overfits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043f9e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:32.149324Z",
     "start_time": "2022-12-01T11:24:25.171175Z"
    },
    "scrolled": false,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 - Initialising the RNN model\n",
    "# ==================================== #\n",
    "model = init_model(X_train, y_train)\n",
    "#model.summary()\n",
    "\n",
    "# 2 - Training\n",
    "# ====================================\n",
    "model, history = fit_model(model, verbose=1)\n",
    "plot_history(history);\n",
    "\n",
    "# 3 - Evaluation\n",
    "# ====================================\n",
    "res = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(f\"The LSTM accuracy on the test set is equal to {round(res[1],2)}, (meaning the model is guessing the correct predictions {round(res[1]*100,2)}% of the time).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923017d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:24:32.553165Z",
     "start_time": "2022-12-01T11:24:32.150946Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57623c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:36:12.380070Z",
     "start_time": "2022-12-01T11:36:12.309587Z"
    }
   },
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test)[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e240f",
   "metadata": {},
   "source": [
    "### (3.2) 🎁 Baseline with a horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42db506",
   "metadata": {},
   "source": [
    "👉 (*Reminder*) ***In Time Series, an \"intuitive\" baseline model is to repeat the last seen value as (a) prediction(s) for the future value(s)*** you want to forecast, as illustrated down below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad086e0b",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/davydw/public-pictures/blob/main/last_seen_value_with_horizon.png?raw=true\" width = 600 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b12de",
   "metadata": {},
   "source": [
    "🎁 **The Last Seen Value Baseline Model** \n",
    "\n",
    "Let's go together through the function `baseline` which:\n",
    "- (_input_) takes a pair $(X, y)$ \n",
    "- (_output_) computes the accuracy of the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfeb6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.775583Z",
     "start_time": "2022-11-30T14:39:34.772023Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # import library\n",
    "\n",
    "def baseline(df):\n",
    "    df['ATMO_baseline'] = df['ATMO'].shift(periods=8,axis=0) #creation of y_pred by shifting target of 7 days\n",
    "    y_baseline = df['ATMO_baseline'][8:] #take off the 7 first values to drop nan\n",
    "    y_true = df['ATMO'][8:] #take off the 7 first values to drop nan\n",
    "    accuracy = accuracy_score(y_true, y_baseline) # use accuracy modul from sklearn\n",
    "    df = df.drop(columns = ['ATMO_baseline'])\n",
    "\n",
    "    return df, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5879df",
   "metadata": {},
   "source": [
    "🕵🏻‍♀️ What is the performance of the \"last seen value baseline model\" on the <font color=orange>**test**</font> set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88970d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.780798Z",
     "start_time": "2022-11-30T14:39:34.777313Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 - Evaluation of the baseline model\n",
    "# ====================================\n",
    "df, accuracy_baseline = baseline(df)\n",
    "\n",
    "print(f\"- The baseline accuracy_baseline on the test set is equal to {round(accuracy_baseline,2)}\")\n",
    "\n",
    "# 4 - Comparison with the LSTM model\n",
    "# ====================================\n",
    "print(f\"- The LSTM accuracy_baseline on the test set is equal to {round(res[1],2)}, (meaning the model is guessing the correct predictions {round(res[1]*100,2)}% of the time).\")\n",
    "print(f\"👉 Improvement/decrease of the LSTM model over the baseline (on this fold for the test set) = : {round(((res[1]-accuracy_baseline)/accuracy_baseline)*100,2)} % 👈\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4edc2",
   "metadata": {},
   "source": [
    "<u><b><i>Warnings:</i></b></u>\n",
    "\n",
    "* <font color=red>***The more data points in the future we try to predict, the lower your accuracy will be!***</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454dc08",
   "metadata": {},
   "source": [
    "### (3.3) 💻 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca699a29",
   "metadata": {},
   "source": [
    "ℹ️ Reminders of the global variables in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ef142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.788288Z",
     "start_time": "2022-11-30T14:39:34.782170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folds\n",
    "print('##### FOLDS ##### ')\n",
    "print(f'- FOLD_LENGTH = {FOLD_LENGTH} timesteps = {1} year x {365} days x {1} record per day + 156 days of test')\n",
    "print(f'- FOLD_STRIDE = {FOLD_STRIDE} timesteps = {(365/4)} days x {1} record per day(s) = sliding each trimester')\n",
    "\n",
    "# Chronological Train Test Split\n",
    "print('##### TRAIN TEST SPLIT #####')\n",
    "print(f'- TRAIN_TEST_RATIO = {TRAIN_TEST_RATIO}')\n",
    "#print(f'- N_TRAIN = {N_TRAIN}')\n",
    "#print(f'- N_TEST = {N_TEST}')\n",
    "\n",
    "# Inputs\n",
    "print('##### INPUTS #####')\n",
    "print(f'- INPUT_LENGTH = {INPUT_LENGTH} timesteps = {int(INPUT_LENGTH)} days x {1} record(s) per day = {int(INPUT_LENGTH/7)} week(s)')\n",
    "print(f'- N_FEATURES = {N_FEATURES}') \n",
    "\n",
    "# Outputs\n",
    "print('##### OUTPUTS #####')\n",
    "print(f'- OUTPUT_LENGTH = {OUTPUT_LENGTH} timesteps = {int(OUTPUT_LENGTH)} day(s) x {1} record(s) per day')\n",
    "print(f\"- Trying to predict:{TARGET}\")\n",
    "print(f'- N_TARGETS = {N_TARGETS}') \n",
    "\n",
    "# Parameters\n",
    "print('##### PARAMETERS #####')\n",
    "print(f'- HORIZON = {HORIZON} timesteps = {int(HORIZON)} day(s) x {8} record(s) per day')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b00e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:34.797101Z",
     "start_time": "2022-11-30T14:39:34.791318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remember how many folds do we have ?\n",
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "print(f\"WARNING, we have {len(folds)} FOLDS, it may take a long time to run...!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ceb68",
   "metadata": {},
   "source": [
    "🎁 **Cross-validating the LSTM and the baseline** \n",
    "\n",
    "_Let's go together through the following code_ 👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef503ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T14:39:59.711962Z",
     "start_time": "2022-11-30T14:39:45.772891Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_accuracy_baseline_model = []\n",
    "list_of_accuracy_recurrent_model = []\n",
    "    \n",
    "# 1 - Creating FOLDS\n",
    "# =======================================================\n",
    "    \n",
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "    \n",
    "for fold_id, fold in enumerate(folds):    \n",
    "    \n",
    "    # 2 - CHRONOLOGICAL TRAIN TEST SPLIT of the current FOLD\n",
    "    # =======================================================    \n",
    "    \n",
    "    (fold_train, fold_test) = train_test_split(fold = fold, \n",
    "                                               train_test_ratio = TRAIN_TEST_RATIO, \n",
    "                                               input_length = INPUT_LENGTH, \n",
    "                                               horizon = HORIZON) \n",
    "    \n",
    "    # 3 - Scanninng fold_train and fold_test for SEQUENCES \n",
    "    # =======================================================       \n",
    "    \n",
    "    X_train, y_train = get_X_y(fold = fold_train, \n",
    "                               horizon = HORIZON, \n",
    "                               input_length = INPUT_LENGTH, \n",
    "                               output_length = OUTPUT_LENGTH, \n",
    "                               stride = STRIDE)\n",
    "    \n",
    "    X_test, y_test = get_X_y(fold_test, \n",
    "                             horizon = HORIZON, \n",
    "                             input_length = INPUT_LENGTH, \n",
    "                             output_length = OUTPUT_LENGTH,\n",
    "                             stride = STRIDE)\n",
    "    \n",
    "    # 4.1 - Baseline Model\n",
    "    # =======================================================\n",
    "    df, accuracy_baseline = baseline(df)\n",
    "        \n",
    "    list_of_accuracy_baseline_model.append(accuracy_baseline)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(f\"Accuracy baseline fold n°{fold_id} = {round(accuracy_baseline, 2)}\")        \n",
    "    \n",
    "    \n",
    "    # 4.2 - LSTM Model\n",
    "    # =======================================================\n",
    "    \n",
    "    # Initializing the LSTM Model\n",
    "    model = init_model(X_train, y_train)\n",
    "    \n",
    "    # Training\n",
    "    model, history = fit_model(model, verbose=0)\n",
    "    \n",
    "    # Evaluation\n",
    "    res = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    accuracy_lstm = res[1]\n",
    "    \n",
    "    list_of_accuracy_recurrent_model.append(accuracy_lstm)\n",
    "    \n",
    "    print(f\"Accuracy LSTM fold n°{fold_id} = {round(accuracy_lstm, 2)}\")\n",
    "    \n",
    "    # 4.3 - Comparison LSTM vs Baseline for the current fold\n",
    "    # =======================================================\n",
    "    print(f\"🏋🏽‍♂️ Improvement/Decrease vs. Baseline: {round(((accuracy_lstm-accuracy_baseline)/accuracy_baseline)*100,2)} % \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_accuracy_recurrent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd50dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T13:17:09.665867Z",
     "start_time": "2022-11-30T13:17:09.125956Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_accuracy_baseline = np.mean(list_of_accuracy_baseline_model)\n",
    "cv_accuracy_lstm = np.mean(list_of_accuracy_recurrent_model)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(f\"Average accuracy baseline = {round(cv_accuracy_baseline, 2)}\")    \n",
    "print(f\"Average accuracy LSTM = {round(cv_accuracy_lstm, 2)}\")    \n",
    "print(f\"🏋🏽‍♂️ Improvement/Decrease vs. Baseline: {round(((cv_accuracy_lstm-cv_accuracy_baseline)/cv_accuracy_baseline)*100,2)} % \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d437fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
