{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 117592\n",
      "-rw-rw-r--@  1 philippemacy  staff     6148 Nov 24 15:08 (1).DS_Store\n",
      "drwxr-xr-x@ 24 philippemacy  staff      768 Nov 28 16:19 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 25 philippemacy  staff      800 Nov 28 16:19 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-rw-r--@  1 philippemacy  staff     6148 Nov 24 15:08 .DS_Store\n",
      "-rw-rw-r--@  1 philippemacy  staff  2561351 Nov 24 15:13 PA75001.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2965830 Nov 24 15:13 PA75002.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3181451 Nov 24 15:13 PA75004.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2755954 Nov 24 15:13 PA75006.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3343070 Nov 24 15:13 PA75007_1.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2783824 Nov 24 15:13 PA75007_2.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3308645 Nov 24 15:13 PA75008.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3244208 Nov 24 15:13 PA75009.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2881234 Nov 24 15:13 PA75012_1.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3268030 Nov 24 15:13 PA75012_2.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2789641 Nov 24 15:13 PA75012_3.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2997587 Nov 24 15:13 PA75013.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2123082 Nov 24 15:13 PA75014.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2714631 Nov 24 15:14 PA75015.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  4028449 Nov 24 15:14 PA75016.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3225916 Nov 24 15:14 PA75018.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3119381 Nov 24 15:14 PA92220.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  2307843 Nov 24 15:14 PA92800.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3321925 Nov 24 15:14 PA93300.csv\n",
      "-rw-rw-r--@  1 philippemacy  staff  3227569 Nov 24 15:14 PA93500.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../data/pollution/2_processed/ && ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dataset in a unique dataset using 'Date_time' as key\n",
    "df_1 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75001.csv')\n",
    "df_2 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75002.csv')\n",
    "df_3 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75004.csv')\n",
    "df_4 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75006.csv')\n",
    "df_5 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75007_1.csv')\n",
    "df_6 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75007_2.csv')\n",
    "df_7 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75008.csv')\n",
    "df_8 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75009.csv')\n",
    "df_9 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75012_1.csv')\n",
    "df_10 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75012_2.csv')\n",
    "df_11 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75012_3.csv')\n",
    "df_12 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75013.csv')\n",
    "df_13 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75014.csv')\n",
    "df_14 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75015.csv')\n",
    "df_15 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75016.csv')\n",
    "df_16 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA75018.csv')\n",
    "df_17 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA92220.csv')\n",
    "df_18 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA92800.csv')\n",
    "df_19 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA93300.csv')\n",
    "df_20 = pd.read_csv('/Users/philippemacy/code/TheLab75/ParisDeepAirProject/data/pollution/2_Processed/PA93500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "merge() got multiple values for argument 'on'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_merge \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(df_1,df_2,df_3,df_4,df_5,df_6,df_7,df_8,df_9,df_10,df_11,df_12,df_13,df_14,df_15,df_16,df_17,df_18,df_19,df_20, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDate_time\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: merge() got multiple values for argument 'on'"
     ]
    }
   ],
   "source": [
    "df_merge = pd.merge(df_1,df_2,df_3,df_4,df_5,df_6,df_7,df_8,df_9,df_10,df_11,df_12,df_13,df_14,df_15,df_16,df_17,df_18,df_19,df_20, on='Date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'Station_type_x', 'NOX_x', 'Unnamed: 0_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'Station_type_x', 'NOX_x', 'Unnamed: 0_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PM10_x', 'Station_name_x', 'NO2_x', 'Station_type_x', 'NOX_x', 'Unnamed: 0_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'Station_type_x', 'NOX_x', 'Unnamed: 0_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'Station_type_x', 'NOX_x', 'Unnamed: 0_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PM10_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'Unnamed: 0_x', 'Station_type_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PM25_x', 'PM10_x', 'NOX_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'O3_x', 'Station_type_x', 'Unnamed: 0_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'NOX_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PM10_x', 'Station_name_x', 'NO2_x', 'Station_type_x', 'Unnamed: 0_x', 'PM25_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'CO_x', 'SO2_x', 'NOX_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n",
      "/var/folders/yp/56r31c5n7dvctsd6b94b6t4w0000gn/T/ipykernel_10918/1902142246.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Station_name_x', 'NO2_x', 'Unnamed: 0_x', 'Station_type_x', 'NO_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')\n"
     ]
    }
   ],
   "source": [
    "df_merge = df_1.merge(df_2, on='Date_time').merge(df_3, on='Date_time').merge(df_4, on='Date_time').merge(df_5, on='Date_time').merge(df_6, on='Date_time').merge(df_7, on='Date_time').merge(df_8, on='Date_time').merge(df_9, on='Date_time').merge(df_10, on='Date_time').merge(df_11, on='Date_time').merge(df_12, on='Date_time').merge(df_13, on='Date_time').merge(df_14, on='Date_time').merge(df_15, on='Date_time').merge(df_16, on='Date_time').merge(df_17, on='Date_time').merge(df_18, on='Date_time').merge(df_19, on='Date_time').merge(df_20, on='Date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33907</th>\n",
       "      <td>2022/11/13 20:00:00+00</td>\n",
       "      <td>0.362</td>\n",
       "      <td>22.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>48.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>2022/11/13 21:00:00+00</td>\n",
       "      <td>0.360</td>\n",
       "      <td>23.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33909</th>\n",
       "      <td>2022/11/13 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>2022/11/13 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>2022/11/14 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33912 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time     CO  PM10  PM25   NO2    NO   NOX   O3\n",
       "0      2019/01/01 01:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "1      2019/01/01 02:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "2      2019/01/01 03:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "3      2019/01/01 04:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "4      2019/01/01 05:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "...                       ...    ...   ...   ...   ...   ...   ...  ...\n",
       "33907  2022/11/13 20:00:00+00  0.362  22.5  19.9  25.4  15.2  48.7  0.1\n",
       "33908  2022/11/13 21:00:00+00  0.360  23.6  21.4  28.5  12.4  47.4  0.1\n",
       "33909  2022/11/13 22:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "33910  2022/11/13 23:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "33911  2022/11/14 00:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN\n",
       "\n",
       "[33912 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_new = df_1.drop(columns=['Station_name','Station_type','Unnamed: 0'], axis = 1)\n",
    "df_1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = [df_1,df_2,df_3,df_4,df_5,df_6,df_7,df_8,df_9,df_10,df_11,df_12,df_13,df_14,df_15,df_16,df_17,df_18,df_19,df_20]\n",
    "\n",
    "def clean(df):\n",
    "    df = df.drop(columns=['Station_type','Unnamed: 0'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Date_time',\n",
       " 'PM10',\n",
       " 'PM25',\n",
       " 'NO2',\n",
       " 'NO',\n",
       " 'NOX',\n",
       " 'Station_name',\n",
       " 'Station_type']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_10.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(df_10.columns)\n",
    "b = [ i+'df' for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0df',\n",
       " 'Date_timedf',\n",
       " 'PM10df',\n",
       " 'PM25df',\n",
       " 'NO2df',\n",
       " 'NOdf',\n",
       " 'NOXdf',\n",
       " 'Station_namedf',\n",
       " 'Station_typedf']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0df</th>\n",
       "      <th>Date_timedf</th>\n",
       "      <th>PM10df</th>\n",
       "      <th>PM25df</th>\n",
       "      <th>NO2df</th>\n",
       "      <th>NOdf</th>\n",
       "      <th>NOXdf</th>\n",
       "      <th>Station_namedf</th>\n",
       "      <th>Station_typedf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>18.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42643</th>\n",
       "      <td>42643</td>\n",
       "      <td>2022/11/14 20:00:00+00</td>\n",
       "      <td>31.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>52.7</td>\n",
       "      <td>108.7</td>\n",
       "      <td>218.4</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42644</th>\n",
       "      <td>42644</td>\n",
       "      <td>2022/11/14 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.9</td>\n",
       "      <td>61.9</td>\n",
       "      <td>141.1</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42645</th>\n",
       "      <td>42645</td>\n",
       "      <td>2022/11/14 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42646</th>\n",
       "      <td>42646</td>\n",
       "      <td>2022/11/14 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42647</th>\n",
       "      <td>42647</td>\n",
       "      <td>2022/11/15 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42648 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0df             Date_timedf  PM10df  PM25df  NO2df   NOdf  \\\n",
       "0                 0  2018/01/01 01:00:00+00    18.1     8.9   13.0    4.0   \n",
       "1                 1  2018/01/01 02:00:00+00    14.7     8.2   15.0    6.0   \n",
       "2                 2  2018/01/01 03:00:00+00    11.6     6.1   20.0    6.0   \n",
       "3                 3  2018/01/01 04:00:00+00    14.4     8.6   25.0    8.0   \n",
       "4                 4  2018/01/01 05:00:00+00    18.2    10.4   25.0    8.0   \n",
       "...             ...                     ...     ...     ...    ...    ...   \n",
       "42643         42643  2022/11/14 20:00:00+00    31.5    21.8   52.7  108.7   \n",
       "42644         42644  2022/11/14 21:00:00+00     NaN     NaN   46.9   61.9   \n",
       "42645         42645  2022/11/14 22:00:00+00     NaN     NaN    NaN    NaN   \n",
       "42646         42646  2022/11/14 23:00:00+00     NaN     NaN    NaN    NaN   \n",
       "42647         42647  2022/11/15 00:00:00+00     NaN     NaN    NaN    NaN   \n",
       "\n",
       "       NOXdf  Station_namedf Station_typedf  \n",
       "0       19.1  75012 - BP Est        Traffic  \n",
       "1       23.6  75012 - BP Est        Traffic  \n",
       "2       28.0  75012 - BP Est        Traffic  \n",
       "3       36.8  75012 - BP Est        Traffic  \n",
       "4       37.3  75012 - BP Est        Traffic  \n",
       "...      ...             ...            ...  \n",
       "42643  218.4  75012 - BP Est        Traffic  \n",
       "42644  141.1  75012 - BP Est        Traffic  \n",
       "42645    NaN  75012 - BP Est        Traffic  \n",
       "42646    NaN  75012 - BP Est        Traffic  \n",
       "42647    NaN  75012 - BP Est        Traffic  \n",
       "\n",
       "[42648 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10.columns = b\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns (df):\n",
    "    column = list(df.columns)\n",
    "    rename = [i+df for i in column]\n",
    "    df.columns = rename\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date_time</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33907</th>\n",
       "      <td>33907</td>\n",
       "      <td>2022/11/13 20:00:00+00</td>\n",
       "      <td>0.362</td>\n",
       "      <td>22.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>48.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>33908</td>\n",
       "      <td>2022/11/13 21:00:00+00</td>\n",
       "      <td>0.360</td>\n",
       "      <td>23.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33909</th>\n",
       "      <td>33909</td>\n",
       "      <td>2022/11/13 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>33910</td>\n",
       "      <td>2022/11/13 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>33911</td>\n",
       "      <td>2022/11/14 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33912 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0               Date_time     CO  PM10  PM25   NO2    NO  \\\n",
       "0               0  2019/01/01 01:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "1               1  2019/01/01 02:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "2               2  2019/01/01 03:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "3               3  2019/01/01 04:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "4               4  2019/01/01 05:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "...           ...                     ...    ...   ...   ...   ...   ...   \n",
       "33907       33907  2022/11/13 20:00:00+00  0.362  22.5  19.9  25.4  15.2   \n",
       "33908       33908  2022/11/13 21:00:00+00  0.360  23.6  21.4  28.5  12.4   \n",
       "33909       33909  2022/11/13 22:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "33910       33910  2022/11/13 23:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "33911       33911  2022/11/14 00:00:00+00    NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "        NOX   O3    Station_name Station_type  \n",
       "0       NaN  NaN  75001 - Halles       Urbain  \n",
       "1       NaN  NaN  75001 - Halles       Urbain  \n",
       "2       NaN  NaN  75001 - Halles       Urbain  \n",
       "3       NaN  NaN  75001 - Halles       Urbain  \n",
       "4       NaN  NaN  75001 - Halles       Urbain  \n",
       "...     ...  ...             ...          ...  \n",
       "33907  48.7  0.1  75001 - Halles       Urbain  \n",
       "33908  47.4  0.1  75001 - Halles       Urbain  \n",
       "33909   NaN  NaN  75001 - Halles       Urbain  \n",
       "33910   NaN  NaN  75001 - Halles       Urbain  \n",
       "33911   NaN  NaN  75001 - Halles       Urbain  \n",
       "\n",
       "[33912 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>Station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33907</th>\n",
       "      <td>2022/11/13 20:00:00+00</td>\n",
       "      <td>0.362</td>\n",
       "      <td>22.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>48.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>2022/11/13 21:00:00+00</td>\n",
       "      <td>0.360</td>\n",
       "      <td>23.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33909</th>\n",
       "      <td>2022/11/13 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>2022/11/13 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>2022/11/14 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33912 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time     CO  PM10  PM25   NO2    NO   NOX   O3  \\\n",
       "0      2019/01/01 01:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1      2019/01/01 02:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2      2019/01/01 03:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3      2019/01/01 04:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4      2019/01/01 05:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "...                       ...    ...   ...   ...   ...   ...   ...  ...   \n",
       "33907  2022/11/13 20:00:00+00  0.362  22.5  19.9  25.4  15.2  48.7  0.1   \n",
       "33908  2022/11/13 21:00:00+00  0.360  23.6  21.4  28.5  12.4  47.4  0.1   \n",
       "33909  2022/11/13 22:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "33910  2022/11/13 23:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "33911  2022/11/14 00:00:00+00    NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "         Station_name  \n",
       "0      75001 - Halles  \n",
       "1      75001 - Halles  \n",
       "2      75001 - Halles  \n",
       "3      75001 - Halles  \n",
       "4      75001 - Halles  \n",
       "...               ...  \n",
       "33907  75001 - Halles  \n",
       "33908  75001 - Halles  \n",
       "33909  75001 - Halles  \n",
       "33910  75001 - Halles  \n",
       "33911  75001 - Halles  \n",
       "\n",
       "[33912 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = clean(df_1)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U9'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rename_columns(df_1)\n",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m, in \u001b[0;36mrename_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrename_columns\u001b[39m (df):\n\u001b[1;32m      2\u001b[0m     column \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m----> 3\u001b[0m     rename \u001b[39m=\u001b[39m [i\u001b[39m+\u001b[39mdf \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m column]\n\u001b[1;32m      4\u001b[0m     df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rename\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrename_columns\u001b[39m (df):\n\u001b[1;32m      2\u001b[0m     column \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m----> 3\u001b[0m     rename \u001b[39m=\u001b[39m [i\u001b[39m+\u001b[39;49mdf \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m column]\n\u001b[1;32m      4\u001b[0m     df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rename\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/arraylike.py:106\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__radd__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__radd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mradd)\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/frame.py:7591\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7587\u001b[0m other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis],))\n\u001b[1;32m   7589\u001b[0m \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_FRAME(\u001b[39mself\u001b[39m, other, axis, flex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 7591\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_frame_op(other, op, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   7592\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/frame.py:7618\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   7615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(right):\n\u001b[1;32m   7616\u001b[0m     \u001b[39m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[1;32m   7617\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 7618\u001b[0m         bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mapply(array_op, right\u001b[39m=\u001b[39;49mright)\n\u001b[1;32m   7619\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(bm)\n\u001b[1;32m   7621\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/internals/managers.py:350\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m callable(f):\n\u001b[0;32m--> 350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39;49mapply(f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/internals/blocks.py:351\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[1;32m    347\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:226\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m    224\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/PDPA-virt_env/lib/python3.10/site-packages/pandas/core/roperator.py:11\u001b[0m, in \u001b[0;36mradd\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradd\u001b[39m(left, right):\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m+\u001b[39;49m left\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U9'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "rename_columns(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2da2dd50209bf47250c1555a576fe22c4934d5fa546a750b2e7c4c4478074087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
