{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f86246",
   "metadata": {},
   "source": [
    "# Paris DeepAir Project - Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749db752",
   "metadata": {},
   "source": [
    "Unité de mesure pour tous les polluants : mg/m3\n",
    "\n",
    "Polluants mesurés :\n",
    "- **CO** : monoxyde de carbone\n",
    "- **NO2** : dioxyde d'azote\n",
    "- **NO**: monoxyde d'azote\n",
    "- **NOX** : oxydes d'azote\n",
    "- **O3** : ozone\n",
    "- **PM 10** : particules\n",
    "- **PM 2,5** : particules fines\n",
    "- **SO2** : dioxyde de souffre\n",
    "\n",
    "Métaux mesurés:\n",
    "- **ETBEN**: ethylbenzene\n",
    "- **m+pXYL**: m+p-xylene\n",
    "- **oXYL**: o-xylene\n",
    "- **TOL**: toluene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7d272",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6252789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67d7254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fd6afff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "drwxr-xr-x@ 28 llm  staff    896 Dec  6 14:44 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Nov 28 13:09 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 llm  staff  14340 Dec  6 13:20 .DS_Store\r\n",
      "drwxr-xr-x@ 23 llm  staff    736 Dec  6 12:16 \u001b[1m\u001b[36m1_Merged\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@ 23 llm  staff    736 Dec  6 12:16 \u001b[1m\u001b[36m2_Processed\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  3 llm  staff     96 Nov 29 15:03 \u001b[1m\u001b[36m3_Concatenated\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  23 llm  staff    736 Dec  6 13:28 \u001b[1m\u001b[36m4_Stations\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  8 llm  staff    256 Dec  6 14:44 \u001b[1m\u001b[36m75001_U_Halles\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:54 \u001b[1m\u001b[36m75002_T_Opera\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:54 \u001b[1m\u001b[36m75004_T_Quai_Celestins\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  8 llm  staff    256 Dec  6 11:55 \u001b[1m\u001b[36m75006_T_Bonap\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:55 \u001b[1m\u001b[36m75007_Obs_Eiffel_3e\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:55 \u001b[1m\u001b[36m75007_U_Allee_R\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:55 \u001b[1m\u001b[36m75008_T_Champs_Elysees\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:56 \u001b[1m\u001b[36m75009_T_Haussmann\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:56 \u001b[1m\u001b[36m75012_T_BP_Est\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:56 \u001b[1m\u001b[36m75012_T_Bd_Soult\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:56 \u001b[1m\u001b[36m75012_U_Rue_BaL\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:58 \u001b[1m\u001b[36m75013_U_Eastman\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  6 llm  staff    192 Dec  6 11:58 \u001b[1m\u001b[36m75014_T_Basch\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:58 \u001b[1m\u001b[36m75015_U_Lenglen\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:58 \u001b[1m\u001b[36m75016_T_Porte_Auteuil\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:59 \u001b[1m\u001b[36m75018_U_Flocon\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:59 \u001b[1m\u001b[36m92220_U_Neuilly\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:59 \u001b[1m\u001b[36m92800_U_La_Defense\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:59 \u001b[1m\u001b[36m93300_U_Aubervilliers\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@  7 llm  staff    224 Dec  6 11:59 \u001b[1m\u001b[36m93500_T_RN2_Pantin\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   6 llm  staff    192 Dec  6 13:00 \u001b[1m\u001b[36minputs\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../../data/pollution && ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66faac7f",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f446999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import pandas as pd\n",
    "\n",
    "def turbo_plot(X):\n",
    "    fig = plt.figure(constrained_layout=True,figsize=(15,120))\n",
    "    subfigs = fig.subfigures(X.shape[1], 1,squeeze=False,hspace=20)\n",
    "    for outerind, subfig in enumerate(subfigs.flat):\n",
    "        subfig.suptitle(f'Subfig {X.columns[outerind]}')\n",
    "        axs = subfig.subplots(1, 3)\n",
    "        sns.histplot(data = X, x = X.columns[outerind], kde=True, ax = axs[0])\n",
    "        sns.boxplot(data = X, x = X.columns[outerind], ax = axs[1])\n",
    "        qqplot(X[X.columns[outerind]],line='s',ax=axs[2])\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f60b68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def mosaic_plot(df,X,y, ax=None):\n",
    "    default_colors =plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    cross = pd.crosstab(df[X],df[y])\n",
    "    couples = cross.unstack().index\n",
    "    props = lambda x: {'facecolor': default_colors[int(x[0])],'edgecolor':'w'}\n",
    "    labelizer = lambda k: {(str(cpl[0]),str(cpl[1])) : f'{cpl[0]}-{cpl[1]}\\n{round(cross.loc[cpl[1],cpl[0]]/cross.loc[:,cpl[0]].sum()*100,2)}%'  for cpl in couples}[k]\n",
    "    mosaic(df, [y, X],properties=props,labelizer = labelizer, ax=ax)\n",
    "    \n",
    "def turbo_plot(df, X, y,classification):\n",
    "    fig = plt.figure(constrained_layout=True,figsize=(15,round(10/3*df.shape[1])))\n",
    "    subfigs = fig.subfigures(X.shape[1], 1,squeeze=False,hspace=20)\n",
    "\n",
    "    for outerind, subfig in enumerate(subfigs.flat):\n",
    "        #plotting numerical features\n",
    "        if X[X.columns[outerind]].dtypes not in ['object','categorical','string'] and round(X[X.columns[outerind]].nunique()/df.shape[0]*100,2)>9:\n",
    "            subfig.suptitle(f'Subfig {X.columns[outerind]}')\n",
    "            axs = subfig.subplots(1, 4)\n",
    "            sns.histplot(data = X, x = X.columns[outerind], kde=True, ax = axs[0])\n",
    "            sns.boxplot(data = X, x = X.columns[outerind], ax = axs[1])\n",
    "            qqplot(X[X.columns[outerind]],line='s',ax=axs[2])\n",
    "            if classification: \n",
    "                sns.stripplot(data = X, x = y, y=X.columns[outerind], hue=y, ax = axs[3])\n",
    "            else: \n",
    "                sns.scatterplot(data = X, x = X.columns[outerind], y=y, ax = axs[3])\n",
    "\n",
    "        #plotting categorical features\n",
    "        else:\n",
    "            subfig.suptitle(f'Subfig {X.columns[outerind]}')\n",
    "            axs = subfig.subplots(1, 4)\n",
    "            sns.countplot(data = X, x = X.columns[outerind], ax = axs[0],order=X[X.columns[outerind]].value_counts().sort_values(ascending=False).index)\n",
    "            sns.countplot(data = X, x = X.columns[outerind], hue=y, ax = axs[1],order=X[X.columns[outerind]].value_counts().sort_values(ascending=False).index)\n",
    "            mosaic_plot(df,X.columns[outerind],df.survived.name,ax=axs[2])\n",
    "            if classification: \n",
    "                sns.stripplot(data = X, x = y, y=X.columns[outerind], hue=y, ax = axs[3])\n",
    "            else:\n",
    "                sns.scatterplot(data = X, x = X.columns[outerind], y=y, ax = axs[3])\n",
    "    return plt.show()\n",
    "\n",
    "def quick_check(df, target:str, classification=True, to_drop=None):\n",
    "    if target not in df.columns:\n",
    "        raise ValueError('target not in df.columns')\n",
    "    if not isinstance(target,str):\n",
    "        raise TypeError('target must str')\n",
    "    if to_drop:\n",
    "        if all(x in df.columns for x in to_drop):\n",
    "            raise ValueError('all elements in to_drop are not in df.columns')\n",
    "\n",
    "        if not isintance(to_drop,list) and isintance(to_drop,str):\n",
    "            to_drop=[to_drop]\n",
    "        else:\n",
    "            raise TypeError('to_drop type must be list of string')\n",
    "    \n",
    "    #Checking nan\n",
    "    check= round(df.isna().sum()/df.shape[0]*100,2).sort_values(ascending=False)\n",
    "    filtered = check[check>0]\n",
    "    print(f'You have : {len(filtered)} features over {len(check)} ({round(check[check>0].shape[0]/check.shape[0],2)}% of whole df) that include np.nan')    \n",
    "\n",
    "    #Features with nan\n",
    "    print(f'\\nHave a look at these features (% of nan): {\", \".join([f\"{i}: {str(v)}%\" for i,v in filtered.items()])}')\n",
    "\n",
    "    #Features to drop\n",
    "    super_drop = check[check>15]\n",
    "    print(f'\\nYou might want to drop these features: {\", \".join(super_drop.index)}')\n",
    "    imputation = df[check[(check>0) & (check<15)].index].dtypes\n",
    "    \n",
    "    print('\\n')\n",
    "    print(df.info())\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Let's have a look at all the features\")\n",
    "    X=df.drop(columns=(target if not to_drop else [target_name]+to_drop))\n",
    "    y=df[target]\n",
    "    turbo_plot(df, X,y,classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c15a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_check2(df, target:str, classification=True, to_drop=None):\n",
    "    if target not in df.columns:\n",
    "        raise ValueError('target not in df.columns')\n",
    "    if not isinstance(target,str):\n",
    "        raise TypeError('target must str')\n",
    "    if to_drop:\n",
    "        if all(x in df.columns for x in to_drop):\n",
    "            raise ValueError('all elements in to_drop are not in df.columns')\n",
    "\n",
    "        if not isintance(to_drop,list) and isintance(to_drop,str):\n",
    "            to_drop=[to_drop]\n",
    "        else:\n",
    "            raise TypeError('to_drop type must be list of string')\n",
    "    \n",
    "    #Checking nan\n",
    "    check= round(df.isna().sum()/df.shape[0]*100,2).sort_values(ascending=False)\n",
    "    filtered = check[check>0]\n",
    "    print(f'You have : {len(filtered)} features over {len(check)} ({round(check[check>0].shape[0]/check.shape[0],2)}% of whole df) that include np.nan')    \n",
    "\n",
    "    #Features with nan\n",
    "    print(f'\\nHave a look at these features (% of nan): {\", \".join([f\"{i}: {str(v)}%\" for i,v in filtered.items()])}')\n",
    "\n",
    "    #Features to drop\n",
    "    super_drop = check[check>15]\n",
    "    print(f'\\nYou might want to drop these features: {\", \".join(super_drop.index)}')\n",
    "    imputation = df[check[(check>0) & (check<15)].index].dtypes\n",
    "    \n",
    "    print('\\n')\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d323a10",
   "metadata": {},
   "source": [
    "## Per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e077d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOCAL_DATA_PATH_pollution = os.path.join(os.path.expanduser('~'), \"code\", \"TheLab75\", \"ParisDeepAirProject\", \"data\", \"pollution\")\n",
    "#LOCAL_DATA_PATH_pollution_merged = os.path.join(os.path.expanduser('~'), \"code\", \"TheLab75\", \"ParisDeepAirProject\", \"data\", \"pollution\", \"1_Merged\")\n",
    "#LOCAL_DATA_PATH_pollution_processed = os.path.join(os.path.expanduser('~'), \"code\", \"TheLab75\", \"ParisDeepAirProject\", \"data\", \"pollution\", \"2_Processed\")\n",
    "\n",
    "LOCAL_DATA_PATH_pollution = '../../data/pollution'\n",
    "LOCAL_DATA_PATH_pollution_merged = '../../data/pollution/1_Merged'\n",
    "LOCAL_DATA_PATH_pollution_processed = '../../data/pollution/2_Processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45f5ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/llm/code/TheLab75/ParisDeepAirProject/data/pollution/df_datetime_init.csv\",delimiter=\";\")\n",
    "df1.to_csv(\"/Users/llm/code/TheLab75/ParisDeepAirProject/data/pollution/df_datetime_ref.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7a585aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/llm/code/TheLab75/ParisDeepAirProject/data/pollution/df_datetime_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe3953cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43200 entries, 0 to 43199\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date_time  43200 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 337.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb3b88",
   "metadata": {},
   "source": [
    "### 75001_U_Halles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "999b36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/llm/code/TheLab75/ParisDeepAirProject/data/pollution/75001_U_Halles/2018_PA01Hc.csv\",delimiter=\";\")\n",
    "df1.to_csv(\"/Users/llm/code/TheLab75/ParisDeepAirProject/data/pollution/75001_U_Halles/2018_PA01H.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eca32427",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75001_U_Halles | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75001 - Halles'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75001 - Halles'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "\n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75001_U_Halles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba69fc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75001 - Halles</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2   O3  SO2    Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "...                       ...   ...   ...   ...  ...  ...             ...   \n",
       "43195  2022/12/05 20:00:00+00  19.0  20.2  24.9  0.2  NaN  75001 - Halles   \n",
       "43196  2022/12/05 21:00:00+00  22.0  24.0  25.9  0.2  NaN  75001 - Halles   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN  NaN  NaN  75001 - Halles   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "43195       Urbain  \n",
       "43196       Urbain  \n",
       "43197       Urbain  \n",
       "43198       Urbain  \n",
       "43199       Urbain  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75001 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75001_U_Halles.csv\", index_col=0).copy()\n",
    "PA75001 = PA75001.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA01H:CO\":\"CO\",\n",
    "    \"PA01H:PM10\":\"PM10\",\n",
    "    \"PA01H:PM25\":\"PM25\",\n",
    "    \"PA01H:NO2\":\"NO2\",\n",
    "    \"PA01H:NO\":\"NO\",\n",
    "    \"PA01H:NOX\":\"NOX\",\n",
    "    \"PA01H:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75001 = PA75001.drop(columns=['CO', 'NO', 'NOX'])\n",
    "PA75001['SO2'] = float('NaN')\n",
    "PA75001 = PA75001[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "488eec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75001.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29c8ecac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): SO2: 100.0%, PM10: 46.71%, NO2: 43.25%, PM25: 41.99%, O3: 37.84%\n",
      "\n",
      "You might want to drop these features: SO2, PM10, NO2, PM25, O3\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          25061 non-null  float64\n",
      " 2   PM10          23020 non-null  float64\n",
      " 3   NO2           24515 non-null  float64\n",
      " 4   O3            26853 non-null  float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75001,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13141c",
   "metadata": {},
   "source": [
    "### 75002_T_Opera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd1a4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75002_T_Opera | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75002 - Opera'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75002 - Opera'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75002_T_Opera.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ed99c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42715</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>29.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42716</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42717</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42718</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42719</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75002 - Opera</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42720 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2   Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "...                       ...   ...   ...   ...  ..  ...            ...   \n",
       "42715  2022/12/05 20:00:00+00   NaN  27.1  29.8 NaN  NaN  75002 - Opera   \n",
       "42716  2022/12/05 21:00:00+00   NaN  25.0  28.5 NaN  NaN  75002 - Opera   \n",
       "42717  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "42718  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "42719  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75002 - Opera   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "42715      Traffic  \n",
       "42716      Traffic  \n",
       "42717      Traffic  \n",
       "42718      Traffic  \n",
       "42719      Traffic  \n",
       "\n",
       "[42720 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75002 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75002_T_Opera.csv\", index_col=0).copy()\n",
    "PA75002 = PA75002.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"OPERA:PM10\":\"PM10\",\n",
    "    \"OPERA:NO2\":\"NO2\",\n",
    "    \"OPERA:NO\":\"NO\",\n",
    "    \"OPERA:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75002 = PA75002.drop(columns=['NO', 'NOX'])\n",
    "PA75002['PM25'] = float('NaN')\n",
    "PA75002['O3'] = float('NaN')\n",
    "PA75002['SO2'] = float('NaN')\n",
    "PA75002 = PA75002[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e45b6bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75002.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75002.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3588ab82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, O3: 100.0%, SO2: 100.0%, PM10: 13.33%, NO2: 2.8%\n",
      "\n",
      "You might want to drop these features: PM25, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42720 entries, 0 to 42719\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     42720 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          37026 non-null  float64\n",
      " 3   NO2           41523 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  42720 non-null  object \n",
      " 7   Station_type  42720 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75002,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377eae0",
   "metadata": {},
   "source": [
    "### 75004_T_Quai_Celestins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60784101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75004_T_Quai_Celestins | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75004 - Quai Celestins'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75004 - Quai Celestins'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75004_T_Quai_Celestins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79859693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43123</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43124</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43125</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43126</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43127</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75004 - Quai Celestins</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43128 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN  21.0 NaN  NaN   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN  16.0 NaN  NaN   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN  16.0 NaN  NaN   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN  15.0 NaN  NaN   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN  12.0 NaN  NaN   \n",
       "...                       ...   ...   ...   ...  ..  ...   \n",
       "43123  2022/12/05 20:00:00+00   NaN   NaN  31.4 NaN  NaN   \n",
       "43124  2022/12/05 21:00:00+00   NaN   NaN  30.5 NaN  NaN   \n",
       "43125  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "43126  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "43127  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "\n",
       "                 Station_name Station_type  \n",
       "0      75004 - Quai Celestins      Traffic  \n",
       "1      75004 - Quai Celestins      Traffic  \n",
       "2      75004 - Quai Celestins      Traffic  \n",
       "3      75004 - Quai Celestins      Traffic  \n",
       "4      75004 - Quai Celestins      Traffic  \n",
       "...                       ...          ...  \n",
       "43123  75004 - Quai Celestins      Traffic  \n",
       "43124  75004 - Quai Celestins      Traffic  \n",
       "43125  75004 - Quai Celestins      Traffic  \n",
       "43126  75004 - Quai Celestins      Traffic  \n",
       "43127  75004 - Quai Celestins      Traffic  \n",
       "\n",
       "[43128 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75004 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75004_T_Quai_Celestins.csv\", index_col=0).copy()\n",
    "PA75004 = PA75004.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"CELES:NO2\":\"NO2\",\n",
    "    \"CELES:NO\":\"NO\",\n",
    "    \"CELES:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75004 = PA75004.drop(columns=['NO', 'NOX'])\n",
    "PA75004['PM25'] = float('NaN')\n",
    "PA75004['PM10'] = float('NaN')\n",
    "PA75004['O3'] = float('NaN')\n",
    "PA75004['SO2'] = float('NaN')\n",
    "PA75004 = PA75004[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e03a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75004.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75004.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9e5ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, O3: 100.0%, SO2: 100.0%, NO2: 3.35%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43128 entries, 0 to 43127\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43128 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           41684 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43128 non-null  object \n",
      " 7   Station_type  43128 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75004,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d4ea5",
   "metadata": {},
   "source": [
    "### 75006_T_Bonap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6510cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75006_T_Bonap | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75006 - Bonap'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75006 - Bonap'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75006_T_Bonap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a76d1f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75006 - Bonap</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2   Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN  25.0 NaN  NaN  75006 - Bonap   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN  21.0 NaN  NaN  75006 - Bonap   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN  24.0 NaN  NaN  75006 - Bonap   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN  23.0 NaN  NaN  75006 - Bonap   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN  20.0 NaN  NaN  75006 - Bonap   \n",
       "...                       ...   ...   ...   ...  ..  ...            ...   \n",
       "43195  2022/12/05 20:00:00+00   NaN   NaN  28.3 NaN  NaN  75006 - Bonap   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  27.6 NaN  NaN  75006 - Bonap   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75006 - Bonap   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75006 - Bonap   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75006 - Bonap   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "43195      Traffic  \n",
       "43196      Traffic  \n",
       "43197      Traffic  \n",
       "43198      Traffic  \n",
       "43199      Traffic  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75006 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75006_T_Bonap.csv\", index_col=0).copy()\n",
    "PA75006 = PA75006.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"BONAP:NO2\":\"NO2\",\n",
    "    \"BONAP:NO\":\"NO\",\n",
    "    \"BONAP:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75006 = PA75006.drop(columns=['NO', 'NOX'])\n",
    "PA75006['PM25'] = float('NaN')\n",
    "PA75006['PM10'] = float('NaN')\n",
    "PA75006['O3'] = float('NaN')\n",
    "PA75006['SO2'] = float('NaN')\n",
    "PA75006 = PA75006[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6748ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75006.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75006.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b6007d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, O3: 100.0%, SO2: 100.0%, NO2: 9.85%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           38945 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75006,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea64f8",
   "metadata": {},
   "source": [
    "### 75007_Obs_Eiffel_3e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce6c8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75007_Obs_Eiffel_3e | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75007 - Eiffel_3e'\n",
    "base['Station_type'] = 'Observatoire'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75007 - Eiffel_3e'\n",
    "    new_df['Station_type'] = 'Observatoire'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_Obs_Eiffel_3e.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74ec2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43003</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43004</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43005</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43006</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43007</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Eiffel_3e</td>\n",
       "      <td>Observatoire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43008 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2    O3  SO2       Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN   2.0  81.0  2.0  75007 - Eiffel_3e   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN   2.0  82.0  1.0  75007 - Eiffel_3e   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN   3.0  77.0  2.0  75007 - Eiffel_3e   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN   3.0  76.0  2.0  75007 - Eiffel_3e   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN   3.0  75.0  1.0  75007 - Eiffel_3e   \n",
       "...                       ...   ...   ...   ...   ...  ...                ...   \n",
       "43003  2022/12/05 20:00:00+00   NaN   NaN  29.8   0.0  NaN  75007 - Eiffel_3e   \n",
       "43004  2022/12/05 21:00:00+00   NaN   NaN  28.8   0.0  NaN  75007 - Eiffel_3e   \n",
       "43005  2022/12/05 22:00:00+00   NaN   NaN   NaN   NaN  NaN  75007 - Eiffel_3e   \n",
       "43006  2022/12/05 23:00:00+00   NaN   NaN   NaN   NaN  NaN  75007 - Eiffel_3e   \n",
       "43007  2022/12/06 00:00:00+00   NaN   NaN   NaN   NaN  NaN  75007 - Eiffel_3e   \n",
       "\n",
       "       Station_type  \n",
       "0      Observatoire  \n",
       "1      Observatoire  \n",
       "2      Observatoire  \n",
       "3      Observatoire  \n",
       "4      Observatoire  \n",
       "...             ...  \n",
       "43003  Observatoire  \n",
       "43004  Observatoire  \n",
       "43005  Observatoire  \n",
       "43006  Observatoire  \n",
       "43007  Observatoire  \n",
       "\n",
       "[43008 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75007_1 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_Obs_Eiffel_3e.csv\", index_col=0).copy()\n",
    "PA75007_1 = PA75007_1.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"EIFF3:NO2\":\"NO2\",\n",
    "    \"EIFF3:SO2\":\"SO2\",\n",
    "    \"EIFF3:NO\":\"NO\",\n",
    "    \"EIFF3:NOX\":\"NOX\",\n",
    "    \"EIFF3:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75007_1 = PA75007_1.drop(columns=['NO', 'NOX'])\n",
    "PA75007_1['PM25'] = float('NaN')\n",
    "PA75007_1['PM10'] = float('NaN')\n",
    "PA75007_1 = PA75007_1[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75007_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb5f3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75007_1.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75007_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ca72fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, SO2: 52.5%, O3: 19.21%, NO2: 7.28%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, SO2, O3\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43008 entries, 0 to 43007\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43008 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           39879 non-null  float64\n",
      " 4   O3            34745 non-null  float64\n",
      " 5   SO2           20430 non-null  float64\n",
      " 6   Station_name  43008 non-null  object \n",
      " 7   Station_type  43008 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75007_1,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc925fa",
   "metadata": {},
   "source": [
    "### 75007_U_Allee_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a3f071e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75007_U_Allee_R | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75007 - Allee_R'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75007 - Allee_R'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_U_Allee_R.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1751eea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/02 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/02 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/02 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/02 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/02 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43171</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43172</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43173</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43174</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43175</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75007 - Allee_R</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43176 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2     Station_name  \\\n",
       "0      2018/01/02 01:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "1      2018/01/02 02:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "2      2018/01/02 03:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "3      2018/01/02 04:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "4      2018/01/02 05:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "...                       ...   ...   ...   ...  ..  ...              ...   \n",
       "43171  2022/12/05 20:00:00+00   NaN   NaN  28.7 NaN  NaN  75007 - Allee_R   \n",
       "43172  2022/12/05 21:00:00+00   NaN   NaN  27.1 NaN  NaN  75007 - Allee_R   \n",
       "43173  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "43174  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "43175  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75007 - Allee_R   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "43171       Urbain  \n",
       "43172       Urbain  \n",
       "43173       Urbain  \n",
       "43174       Urbain  \n",
       "43175       Urbain  \n",
       "\n",
       "[43176 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75007_2 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_U_Allee_R.csv\", index_col=0).copy()\n",
    "PA75007_2 = PA75007_2.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA07:NO2\":\"NO2\",\n",
    "    \"PA07:NO\":\"NO\",\n",
    "    \"PA07:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75007_2 = PA75007_2.drop(columns=['NO', 'NOX'])\n",
    "PA75007_2['PM25'] = float('NaN')\n",
    "PA75007_2['PM10'] = float('NaN')\n",
    "PA75007_2['O3'] = float('NaN')\n",
    "PA75007_2['SO2'] = float('NaN')\n",
    "PA75007_2 = PA75007_2[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75007_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28039adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75007_2.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75007_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "094e913f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, O3: 100.0%, SO2: 100.0%, NO2: 3.42%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43176 entries, 0 to 43175\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43176 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           41699 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43176 non-null  object \n",
      " 7   Station_type  43176 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75007_2,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea78c4e",
   "metadata": {},
   "source": [
    "### 75008_T_Champs_Elysees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b250f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75008_T_Champs_Elysees | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75008 - Champs Elysees'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75008 - Champs Elysees'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75008_T_Champs_Elysees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c6e7f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42907</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.2</td>\n",
       "      <td>26.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42908</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42909</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42910</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42911</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75008 - Champs Elysees</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42912 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  21.3  20.0 NaN  NaN   \n",
       "1      2018/01/01 02:00:00+00   NaN  30.1  52.0 NaN  NaN   \n",
       "2      2018/01/01 03:00:00+00   NaN  29.4  31.0 NaN  NaN   \n",
       "3      2018/01/01 04:00:00+00   NaN  24.6  34.0 NaN  NaN   \n",
       "4      2018/01/01 05:00:00+00   NaN  22.1  22.0 NaN  NaN   \n",
       "...                       ...   ...   ...   ...  ..  ...   \n",
       "42907  2022/12/05 20:00:00+00   NaN  27.2  26.7 NaN  NaN   \n",
       "42908  2022/12/05 21:00:00+00   NaN   NaN  25.8 NaN  NaN   \n",
       "42909  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "42910  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "42911  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "\n",
       "                 Station_name Station_type  \n",
       "0      75008 - Champs Elysees      Traffic  \n",
       "1      75008 - Champs Elysees      Traffic  \n",
       "2      75008 - Champs Elysees      Traffic  \n",
       "3      75008 - Champs Elysees      Traffic  \n",
       "4      75008 - Champs Elysees      Traffic  \n",
       "...                       ...          ...  \n",
       "42907  75008 - Champs Elysees      Traffic  \n",
       "42908  75008 - Champs Elysees      Traffic  \n",
       "42909  75008 - Champs Elysees      Traffic  \n",
       "42910  75008 - Champs Elysees      Traffic  \n",
       "42911  75008 - Champs Elysees      Traffic  \n",
       "\n",
       "[42912 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75008 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75008_T_Champs_Elysees.csv\", index_col=0).copy()\n",
    "PA75008 = PA75008.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"ELYS:PM10\":\"PM10\",\n",
    "    \"ELYS:NO2\":\"NO2\",\n",
    "    \"ELYS:NO\":\"NO\",\n",
    "    \"ELYS:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75008 = PA75008.drop(columns=['NO', 'NOX'])\n",
    "PA75008['PM25'] = float('NaN')\n",
    "PA75008['O3'] = float('NaN')\n",
    "PA75008['SO2'] = float('NaN')\n",
    "PA75008 = PA75008[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fa7c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75008.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75008.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "275f32af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, O3: 100.0%, SO2: 100.0%, PM10: 17.18%, NO2: 5.8%\n",
      "\n",
      "You might want to drop these features: PM25, O3, SO2, PM10\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42912 entries, 0 to 42911\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     42912 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          35538 non-null  float64\n",
      " 3   NO2           40423 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  42912 non-null  object \n",
      " 7   Station_type  42912 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75008,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b06da",
   "metadata": {},
   "source": [
    "### 75009_T_Haussmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "097698ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75009_T_Haussmann | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75009 - Haussmann'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75009 - Haussmann'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75009_T_Haussmann.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "303ffd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>27.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75009 - Haussmann</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2       Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  19.3  53.0 NaN  NaN  75009 - Haussmann   \n",
       "1      2018/01/01 02:00:00+00   NaN  20.0  44.0 NaN  NaN  75009 - Haussmann   \n",
       "2      2018/01/01 03:00:00+00   NaN  24.3  46.0 NaN  NaN  75009 - Haussmann   \n",
       "3      2018/01/01 04:00:00+00   NaN  21.4  40.0 NaN  NaN  75009 - Haussmann   \n",
       "4      2018/01/01 05:00:00+00   NaN  21.8  34.0 NaN  NaN  75009 - Haussmann   \n",
       "...                       ...   ...   ...   ...  ..  ...                ...   \n",
       "43195  2022/12/05 20:00:00+00  19.0  25.8  27.3 NaN  NaN  75009 - Haussmann   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  25.0 NaN  NaN  75009 - Haussmann   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75009 - Haussmann   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75009 - Haussmann   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75009 - Haussmann   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "43195      Traffic  \n",
       "43196      Traffic  \n",
       "43197      Traffic  \n",
       "43198      Traffic  \n",
       "43199      Traffic  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75009 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75009_T_Haussmann.csv\", index_col=0).copy()\n",
    "PA75009 = PA75009.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"HAUS:PM10\":\"PM10\",\n",
    "    \"HAUS:PM25\":\"PM25\",\n",
    "    \"HAUS:NO2\":\"NO2\",\n",
    "    \"HAUS:NO\":\"NO\",\n",
    "    \"HAUS:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75009 = PA75009.iloc[:, [0, 7, 1, 2, 3, 4, 5, 6]]\n",
    "PA75009 = PA75009.drop(columns=['NO', 'NOX'])\n",
    "PA75009['O3'] = float('NaN')\n",
    "PA75009['SO2'] = float('NaN')\n",
    "PA75009 = PA75009[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab7c93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75009.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75009.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a01b0a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): O3: 100.0%, SO2: 100.0%, PM25: 81.38%, NO2: 1.91%, PM10: 1.74%\n",
      "\n",
      "You might want to drop these features: O3, SO2, PM25\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          8046 non-null   float64\n",
      " 2   PM10          42450 non-null  float64\n",
      " 3   NO2           42374 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75009,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf89f1",
   "metadata": {},
   "source": [
    "### 75012_T_Bd_Soult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68c9a274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75012_T_Bd_Soult | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75012 - Bd Soult'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75012 - Bd Soult'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_Bd_Soult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e744130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43027</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43028</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43029</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43030</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43031</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Bd Soult</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43032 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2      Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN  14.0 NaN  NaN  75012 - Bd Soult   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN  14.0 NaN  NaN  75012 - Bd Soult   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN  16.0 NaN  NaN  75012 - Bd Soult   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN  20.0 NaN  NaN  75012 - Bd Soult   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN  18.0 NaN  NaN  75012 - Bd Soult   \n",
       "...                       ...   ...   ...   ...  ..  ...               ...   \n",
       "43027  2022/12/05 20:00:00+00   NaN   NaN  27.7 NaN  NaN  75012 - Bd Soult   \n",
       "43028  2022/12/05 21:00:00+00   NaN   NaN  28.4 NaN  NaN  75012 - Bd Soult   \n",
       "43029  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - Bd Soult   \n",
       "43030  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - Bd Soult   \n",
       "43031  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - Bd Soult   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "43027      Traffic  \n",
       "43028      Traffic  \n",
       "43029      Traffic  \n",
       "43030      Traffic  \n",
       "43031      Traffic  \n",
       "\n",
       "[43032 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75012_1 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_Bd_Soult.csv\", index_col=0).copy()\n",
    "PA75012_1 = PA75012_1.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"SOULT:NO2\":\"NO2\",\n",
    "    \"SOULT:NO\":\"NO\",\n",
    "    \"SOULT:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75012_1 = PA75012_1.drop(columns=['NO', 'NOX'])\n",
    "PA75012_1['PM25'] = float('NaN')\n",
    "PA75012_1['PM10'] = float('NaN')\n",
    "PA75012_1['O3'] = float('NaN')\n",
    "PA75012_1['SO2'] = float('NaN')\n",
    "PA75012_1 = PA75012_1[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75012_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8efd96c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75012_1.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75012_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb38ed44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, O3: 100.0%, SO2: 100.0%, NO2: 4.96%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43032 entries, 0 to 43031\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43032 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           40897 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43032 non-null  object \n",
      " 7   Station_type  43032 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75012_1,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3967d",
   "metadata": {},
   "source": [
    "### 75012_T_BP_Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1333d5f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75012_T_BP_Est | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75012 - BP Est'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75012 - BP Est'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_BP_Est.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e859d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>8.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>8.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>10.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43147</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43148</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43149</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43150</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43151</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - BP Est</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43152 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2    Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   8.9  18.1  13.0 NaN  NaN  75012 - BP Est   \n",
       "1      2018/01/01 02:00:00+00   8.2  14.7  15.0 NaN  NaN  75012 - BP Est   \n",
       "2      2018/01/01 03:00:00+00   6.1  11.6  20.0 NaN  NaN  75012 - BP Est   \n",
       "3      2018/01/01 04:00:00+00   8.6  14.4  25.0 NaN  NaN  75012 - BP Est   \n",
       "4      2018/01/01 05:00:00+00  10.4  18.2  25.0 NaN  NaN  75012 - BP Est   \n",
       "...                       ...   ...   ...   ...  ..  ...             ...   \n",
       "43147  2022/12/05 20:00:00+00  24.0  38.0  44.6 NaN  NaN  75012 - BP Est   \n",
       "43148  2022/12/05 21:00:00+00   NaN   NaN  48.3 NaN  NaN  75012 - BP Est   \n",
       "43149  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - BP Est   \n",
       "43150  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - BP Est   \n",
       "43151  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - BP Est   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "43147      Traffic  \n",
       "43148      Traffic  \n",
       "43149      Traffic  \n",
       "43150      Traffic  \n",
       "43151      Traffic  \n",
       "\n",
       "[43152 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75012_2 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_BP_Est.csv\", index_col=0).copy()\n",
    "PA75012_2 = PA75012_2.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"BP_EST:PM10\":\"PM10\",\n",
    "    \"BP_EST:PM25\":\"PM25\",\n",
    "    \"BP_EST:NO2\":\"NO2\",\n",
    "    \"BP_EST:NO\":\"NO\",\n",
    "    \"BP_EST:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75012_2 = PA75012_2.drop(columns=['NO', 'NOX'])\n",
    "PA75012_2['O3'] = float('NaN')\n",
    "PA75012_2['SO2'] = float('NaN')\n",
    "PA75012_2 = PA75012_2[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75012_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8c51530",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75012_2.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75012_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "616d5a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): O3: 100.0%, SO2: 100.0%, PM25: 2.98%, NO2: 2.41%, PM10: 2.19%\n",
      "\n",
      "You might want to drop these features: O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43152 entries, 0 to 43151\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43152 non-null  object \n",
      " 1   PM25          41864 non-null  float64\n",
      " 2   PM10          42208 non-null  float64\n",
      " 3   NO2           42112 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43152 non-null  object \n",
      " 7   Station_type  43152 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75012_2,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf2f2d",
   "metadata": {},
   "source": [
    "### 75012_U_Rue_BaL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7d60178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75012_U_Rue_BaL | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75012 - Rue BaL'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75012 - Rue BaL'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_U_Rue_BaL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afabc3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75012 - Rue BaL</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2     Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN   8.0 NaN  NaN  75012 - Rue BaL   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN  10.0 NaN  NaN  75012 - Rue BaL   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN   9.0 NaN  NaN  75012 - Rue BaL   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN   9.0 NaN  NaN  75012 - Rue BaL   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN   9.0 NaN  NaN  75012 - Rue BaL   \n",
       "...                       ...   ...   ...   ...  ..  ...              ...   \n",
       "43195  2022/12/05 20:00:00+00   NaN   NaN  29.8 NaN  NaN  75012 - Rue BaL   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  30.2 NaN  NaN  75012 - Rue BaL   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - Rue BaL   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - Rue BaL   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75012 - Rue BaL   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "43195       Urbain  \n",
       "43196       Urbain  \n",
       "43197       Urbain  \n",
       "43198       Urbain  \n",
       "43199       Urbain  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75012_3 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_U_Rue_BaL.csv\", index_col=0).copy()\n",
    "PA75012_3 = PA75012_3.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA12:NO2\":\"NO2\",\n",
    "    \"PA12:NO\":\"NO\",\n",
    "    \"PA12:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75012_3 = PA75012_3.drop(columns=['NO', 'NOX'])\n",
    "PA75012_3['PM25'] = float('NaN')\n",
    "PA75012_3['PM10'] = float('NaN')\n",
    "PA75012_3['O3'] = float('NaN')\n",
    "PA75012_3['SO2'] = float('NaN')\n",
    "PA75012_3 = PA75012_3[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75012_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79a9f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75012_3.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75012_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "add1622c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, O3: 100.0%, SO2: 100.0%, NO2: 3.85%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           41537 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75012_3,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae572d34",
   "metadata": {},
   "source": [
    "### 75013_U_Eastman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7cdffb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75013_U_Eastman | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75013 - Eastman'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75013 - Eastman'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75013_U_Eastman.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c84a2542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75013 - Eastman</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2    O3  SO2     Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN   9.0  73.0  NaN  75013 - Eastman   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN   9.0  73.0  NaN  75013 - Eastman   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN  11.0  70.0  NaN  75013 - Eastman   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN  11.0  67.0  NaN  75013 - Eastman   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN  10.0  66.0  NaN  75013 - Eastman   \n",
       "...                       ...   ...   ...   ...   ...  ...              ...   \n",
       "43195  2022/12/05 20:00:00+00   NaN   NaN  25.1   2.3  NaN  75013 - Eastman   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  25.3   2.6  NaN  75013 - Eastman   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN   NaN  NaN  75013 - Eastman   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN   NaN  NaN  75013 - Eastman   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN   NaN  NaN  75013 - Eastman   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "43195       Urbain  \n",
       "43196       Urbain  \n",
       "43197       Urbain  \n",
       "43198       Urbain  \n",
       "43199       Urbain  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75013 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75013_U_Eastman.csv\", index_col=0).copy()\n",
    "PA75013 = PA75013.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA13:NO2\":\"NO2\",\n",
    "    \"PA13:NO\":\"NO\",\n",
    "    \"PA13:NOX\":\"NOX\",\n",
    "    \"PA13:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75013 = PA75013.drop(columns=['NO', 'NOX'])\n",
    "PA75013['PM25'] = float('NaN')\n",
    "PA75013['PM10'] = float('NaN')\n",
    "PA75013['SO2'] = float('NaN')\n",
    "PA75013 = PA75013[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7588e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75013.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75013.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc17eafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, SO2: 100.0%, NO2: 2.58%, O3: 1.41%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           42085 non-null  float64\n",
      " 4   O3            42592 non-null  float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75013,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f538f",
   "metadata": {},
   "source": [
    "### 75014_T_Basch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "946e87ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75014_T_Basch | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75014 - Basch'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75014 - Basch'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75014_T_Basch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "286be2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29467</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29468</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29469</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29470</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29471</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75014 - Basch</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29472 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2   Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  19.8  23.0 NaN  NaN  75014 - Basch   \n",
       "1      2018/01/01 02:00:00+00   NaN  14.0  23.0 NaN  NaN  75014 - Basch   \n",
       "2      2018/01/01 03:00:00+00   NaN  14.9  30.0 NaN  NaN  75014 - Basch   \n",
       "3      2018/01/01 04:00:00+00   NaN  19.9  27.0 NaN  NaN  75014 - Basch   \n",
       "4      2018/01/01 05:00:00+00   NaN  21.4  25.0 NaN  NaN  75014 - Basch   \n",
       "...                       ...   ...   ...   ...  ..  ...            ...   \n",
       "29467  2022/12/05 20:00:00+00   NaN  32.0  29.5 NaN  NaN  75014 - Basch   \n",
       "29468  2022/12/05 21:00:00+00   NaN   NaN  31.9 NaN  NaN  75014 - Basch   \n",
       "29469  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  75014 - Basch   \n",
       "29470  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75014 - Basch   \n",
       "29471  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75014 - Basch   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "29467      Traffic  \n",
       "29468      Traffic  \n",
       "29469      Traffic  \n",
       "29470      Traffic  \n",
       "29471      Traffic  \n",
       "\n",
       "[29472 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75014 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75014_T_Basch.csv\", index_col=0).copy()\n",
    "PA75014 = PA75014.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"BASCH:CO\":\"CO\",\n",
    "    \"BASCH:PM10\":\"PM10\",\n",
    "    \"BASCH:NO2\":\"NO2\",\n",
    "    \"BASCH:NO\":\"NO\",\n",
    "    \"BASCH:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75014 = PA75014.drop(columns=['CO', 'NO', 'NOX'])\n",
    "PA75014['PM25'] = float('NaN')\n",
    "PA75014['O3'] = float('NaN')\n",
    "PA75014['SO2'] = float('NaN')\n",
    "PA75014 = PA75014[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9791239",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75014.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75014.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a945ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, O3: 100.0%, SO2: 100.0%, NO2: 5.36%, PM10: 4.58%\n",
      "\n",
      "You might want to drop these features: PM25, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29472 entries, 0 to 29471\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     29472 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          28121 non-null  float64\n",
      " 3   NO2           27891 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  29472 non-null  object \n",
      " 7   Station_type  29472 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75014,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44936e3c",
   "metadata": {},
   "source": [
    "### 75015_U_Lenglen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "763a66c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75015_U_Lenglen | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75015 - Lenglen'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75015 - Lenglen'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75015_U_Lenglen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4820ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42667</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.9</td>\n",
       "      <td>32.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42668</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42669</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42670</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42671</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75015 - Lenglen</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42672 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2     Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  14.7   4.0 NaN  NaN  75015 - Lenglen   \n",
       "1      2018/01/01 02:00:00+00   NaN  14.1   4.0 NaN  NaN  75015 - Lenglen   \n",
       "2      2018/01/01 03:00:00+00   NaN  11.2   4.0 NaN  NaN  75015 - Lenglen   \n",
       "3      2018/01/01 04:00:00+00   NaN  12.8   4.0 NaN  NaN  75015 - Lenglen   \n",
       "4      2018/01/01 05:00:00+00   NaN  16.2   4.0 NaN  NaN  75015 - Lenglen   \n",
       "...                       ...   ...   ...   ...  ..  ...              ...   \n",
       "42667  2022/12/05 20:00:00+00   NaN  21.9  32.3 NaN  NaN  75015 - Lenglen   \n",
       "42668  2022/12/05 21:00:00+00   NaN  23.6  31.0 NaN  NaN  75015 - Lenglen   \n",
       "42669  2022/12/05 22:00:00+00   NaN   NaN  29.4 NaN  NaN  75015 - Lenglen   \n",
       "42670  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  75015 - Lenglen   \n",
       "42671  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  75015 - Lenglen   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "42667       Urbain  \n",
       "42668       Urbain  \n",
       "42669       Urbain  \n",
       "42670       Urbain  \n",
       "42671       Urbain  \n",
       "\n",
       "[42672 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75015 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75015_U_Lenglen.csv\", index_col=0).copy()\n",
    "PA75015 = PA75015.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA15L:PM10\":\"PM10\",\n",
    "    \"PA15L:NO2\":\"NO2\",\n",
    "    \"PA15L:NO\":\"NO\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75015 = PA75015.drop(columns=['NO'])\n",
    "PA75015['PM25'] = float('NaN')\n",
    "PA75015['O3'] = float('NaN')\n",
    "PA75015['SO2'] = float('NaN')\n",
    "PA75015 = PA75015[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a74296b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75015.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaba6aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, O3: 100.0%, SO2: 100.0%, PM10: 18.22%, NO2: 4.49%\n",
      "\n",
      "You might want to drop these features: PM25, O3, SO2, PM10\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42672 entries, 0 to 42671\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     42672 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          34898 non-null  float64\n",
      " 3   NO2           40755 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  42672 non-null  object \n",
      " 7   Station_type  42672 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75015,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7c4ac",
   "metadata": {},
   "source": [
    "### 75016_T_Porte_Auteuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a6ec7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75016_T_Porte_Auteuil | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75016 - Porte Auteuil'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75016 - Porte Auteuil'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75016_T_Porte_Auteuil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc594acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43075</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>20.8</td>\n",
       "      <td>25.3</td>\n",
       "      <td>36.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43076</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43077</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43078</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43079</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75016 - Porte Auteuil</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43080 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "...                       ...   ...   ...   ...  ..  ...   \n",
       "43075  2022/12/05 20:00:00+00  20.8  25.3  36.2 NaN  NaN   \n",
       "43076  2022/12/05 21:00:00+00   NaN   NaN  32.3 NaN  NaN   \n",
       "43077  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "43078  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "43079  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "\n",
       "                Station_name Station_type  \n",
       "0      75016 - Porte Auteuil      Traffic  \n",
       "1      75016 - Porte Auteuil      Traffic  \n",
       "2      75016 - Porte Auteuil      Traffic  \n",
       "3      75016 - Porte Auteuil      Traffic  \n",
       "4      75016 - Porte Auteuil      Traffic  \n",
       "...                      ...          ...  \n",
       "43075  75016 - Porte Auteuil      Traffic  \n",
       "43076  75016 - Porte Auteuil      Traffic  \n",
       "43077  75016 - Porte Auteuil      Traffic  \n",
       "43078  75016 - Porte Auteuil      Traffic  \n",
       "43079  75016 - Porte Auteuil      Traffic  \n",
       "\n",
       "[43080 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75016 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75016_T_Porte_Auteuil.csv\", index_col=0).copy()\n",
    "PA75016 = PA75016.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"AUT:CO\":\"CO\",\n",
    "    \"AUT:PM10\":\"PM10\",\n",
    "    \"AUT:PM25\":\"PM25\",\n",
    "    \"AUT:NO2\":\"NO2\",\n",
    "    \"AUT:SO2\":\"SO2\",\n",
    "    \"AUT:ETBEN\":\"ETBEN\",\n",
    "    \"AUT:m+pXYL\":\"m+pXYL\",\n",
    "    \"AUT:NO\":\"NO\",\n",
    "    \"AUT:oXYL\":\"oXYL\",\n",
    "    \"AUT:NOX\":\"NOX\",\n",
    "    \"AUT:TOL\":\"TOL\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75016 = PA75016.drop(columns=['CO', 'NO', 'NOX', 'ETBEN', 'm+pXYL', 'oXYL', 'TOL'])\n",
    "PA75016['O3'] = float('NaN')\n",
    "PA75016 = PA75016[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24522c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75016.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75016.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe59c7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): O3: 100.0%, SO2: 40.94%, NO2: 4.84%, PM25: 3.1%, PM10: 2.73%\n",
      "\n",
      "You might want to drop these features: O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43080 entries, 0 to 43079\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43080 non-null  object \n",
      " 1   PM25          41745 non-null  float64\n",
      " 2   PM10          41904 non-null  float64\n",
      " 3   NO2           40996 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           25444 non-null  float64\n",
      " 6   Station_name  43080 non-null  object \n",
      " 7   Station_type  43080 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75016,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cfded5",
   "metadata": {},
   "source": [
    "### 75018_U_Flocon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "023e1e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/75018_U_Flocon | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75018 - Flocon'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75018 - Flocon'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75018_U_Flocon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5c402fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>24.5</td>\n",
       "      <td>26.4</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>26.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75018 - Flocon</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2    O3  SO2    Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  14.2  14.0  66.0  NaN  75018 - Flocon   \n",
       "1      2018/01/01 02:00:00+00   NaN  13.0  14.0  66.0  NaN  75018 - Flocon   \n",
       "2      2018/01/01 03:00:00+00   NaN  11.6  14.0  64.0  NaN  75018 - Flocon   \n",
       "3      2018/01/01 04:00:00+00   NaN  11.9  15.0  62.0  NaN  75018 - Flocon   \n",
       "4      2018/01/01 05:00:00+00   NaN  14.5  14.0  62.0  NaN  75018 - Flocon   \n",
       "...                       ...   ...   ...   ...   ...  ...             ...   \n",
       "43195  2022/12/05 20:00:00+00  24.5  26.4  29.7   1.3  NaN  75018 - Flocon   \n",
       "43196  2022/12/05 21:00:00+00  26.7  31.6  27.5   1.2  NaN  75018 - Flocon   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN   NaN  NaN  75018 - Flocon   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN   NaN  NaN  75018 - Flocon   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN   NaN  NaN  75018 - Flocon   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "43195       Urbain  \n",
       "43196       Urbain  \n",
       "43197       Urbain  \n",
       "43198       Urbain  \n",
       "43199       Urbain  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA75018 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75018_U_Flocon.csv\", index_col=0).copy()\n",
    "PA75018 = PA75018.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA18:PM10\":\"PM10\",\n",
    "    \"PA18:NO2\":\"NO2\",\n",
    "    \"PA18:NO\":\"NO\",\n",
    "    \"PA18:NOX\":\"NOX\",\n",
    "    \"PA18:O3\":\"O3\",\n",
    "    \"PA18:PM25\":\"PM25\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75018 = PA75018.iloc[:, [0, 8, 1, 2, 3, 4, 5, 6, 7]]\n",
    "PA75018 = PA75018.drop(columns=['NO', 'NOX'])\n",
    "PA75018['SO2'] = float('NaN')\n",
    "PA75018 = PA75018[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab5f47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA75018.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75018.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca63d50c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): SO2: 100.0%, PM25: 82.54%, PM10: 3.76%, NO2: 3.27%, O3: 2.11%\n",
      "\n",
      "You might want to drop these features: SO2, PM25\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          7543 non-null   float64\n",
      " 2   PM10          41577 non-null  float64\n",
      " 3   NO2           41788 non-null  float64\n",
      " 4   O3            42287 non-null  float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA75018,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6d083",
   "metadata": {},
   "source": [
    "### 92220_U_Neuilly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fdb1b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/92220_U_Neuilly | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '92220 - Neuilly'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '92220 - Neuilly'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92220_U_Neuilly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8c2e369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92220 - Neuilly</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2    O3  SO2     Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN  11.0  74.0  1.0  92220 - Neuilly   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN  11.0  75.0  1.0  92220 - Neuilly   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN  13.0  71.0  1.0  92220 - Neuilly   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN  15.0  66.0  1.0  92220 - Neuilly   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN  12.0  68.0  1.0  92220 - Neuilly   \n",
       "...                       ...   ...   ...   ...   ...  ...              ...   \n",
       "43195  2022/12/05 20:00:00+00   NaN   NaN  24.8   1.8  NaN  92220 - Neuilly   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  24.6   1.5  NaN  92220 - Neuilly   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN   NaN  NaN  92220 - Neuilly   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN   NaN  NaN  92220 - Neuilly   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN   NaN  NaN  92220 - Neuilly   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "43195       Urbain  \n",
       "43196       Urbain  \n",
       "43197       Urbain  \n",
       "43198       Urbain  \n",
       "43199       Urbain  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA92220 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92220_U_Neuilly.csv\", index_col=0).copy()\n",
    "PA92220 = PA92220.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"NEUIL:NO2\":\"NO2\",\n",
    "    \"NEUIL:SO2\":\"SO2\",\n",
    "    \"NEUIL:NO\":\"NO\",\n",
    "    \"NEUIL:NOX\":\"NOX\",\n",
    "    \"NEUIL:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA92220 = PA92220.drop(columns=['NO', 'NOX'])\n",
    "PA92220['PM25'] = float('NaN')\n",
    "PA92220['PM10'] = float('NaN')\n",
    "PA92220 = PA92220[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA92220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de02174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA92220.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA92220.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "617cadad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, SO2: 38.43%, NO2: 4.29%, O3: 1.56%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           41345 non-null  float64\n",
      " 4   O3            42527 non-null  float64\n",
      " 5   SO2           26599 non-null  float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA92220,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8328314",
   "metadata": {},
   "source": [
    "### 92800_U_La_Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d07adddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/92800_U_La_Defense | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '92800 - La Defense'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '92800 - La Defense'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92800_U_La_Defense.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7f8f867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33019</th>\n",
       "      <td>2022/12/04 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33020</th>\n",
       "      <td>2022/12/04 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33021</th>\n",
       "      <td>2022/12/04 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33022</th>\n",
       "      <td>2022/12/04 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>2022/12/05 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92800 - La Defense</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33024 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10  NO2  O3  SO2        Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  12.6  5.0 NaN  NaN  92800 - La Defense   \n",
       "1      2018/01/01 02:00:00+00   NaN  10.1  5.0 NaN  NaN  92800 - La Defense   \n",
       "2      2018/01/01 03:00:00+00   NaN  11.3  5.0 NaN  NaN  92800 - La Defense   \n",
       "3      2018/01/01 04:00:00+00   NaN  10.2  7.0 NaN  NaN  92800 - La Defense   \n",
       "4      2018/01/01 05:00:00+00   NaN  11.6  6.0 NaN  NaN  92800 - La Defense   \n",
       "...                       ...   ...   ...  ...  ..  ...                 ...   \n",
       "33019  2022/12/04 20:00:00+00   NaN   NaN  NaN NaN  NaN  92800 - La Defense   \n",
       "33020  2022/12/04 21:00:00+00   NaN   NaN  NaN NaN  NaN  92800 - La Defense   \n",
       "33021  2022/12/04 22:00:00+00   NaN   NaN  NaN NaN  NaN  92800 - La Defense   \n",
       "33022  2022/12/04 23:00:00+00   NaN   NaN  NaN NaN  NaN  92800 - La Defense   \n",
       "33023  2022/12/05 00:00:00+00   NaN   NaN  NaN NaN  NaN  92800 - La Defense   \n",
       "\n",
       "      Station_type  \n",
       "0           Urbain  \n",
       "1           Urbain  \n",
       "2           Urbain  \n",
       "3           Urbain  \n",
       "4           Urbain  \n",
       "...            ...  \n",
       "33019       Urbain  \n",
       "33020       Urbain  \n",
       "33021       Urbain  \n",
       "33022       Urbain  \n",
       "33023       Urbain  \n",
       "\n",
       "[33024 rows x 8 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA92800 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92800_U_La_Defense.csv\", index_col=0).copy()\n",
    "PA92800 = PA92800.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"DEF:PM10\":\"PM10\",\n",
    "    \"DEF:PM25\":\"PM25\",\n",
    "    \"DEF:NO2\":\"NO2\",\n",
    "    \"DEF:NO\":\"NO\",\n",
    "    \"DEF:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA92800 = PA92800.iloc[:, [0, 7, 1, 2, 3, 4, 5, 6]]\n",
    "PA92800 = PA92800.drop(columns=['NO', 'NOX'])\n",
    "PA92800['O3'] = float('NaN')\n",
    "PA92800['SO2'] = float('NaN')\n",
    "PA92800 = PA92800[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA92800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f15f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA92800.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA92800.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35b0cf12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): O3: 100.0%, SO2: 100.0%, PM25: 96.46%, PM10: 45.42%, NO2: 26.22%\n",
      "\n",
      "You might want to drop these features: O3, SO2, PM25, PM10, NO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33024 entries, 0 to 33023\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     33024 non-null  object \n",
      " 1   PM25          1170 non-null   float64\n",
      " 2   PM10          18024 non-null  float64\n",
      " 3   NO2           24366 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  33024 non-null  object \n",
      " 7   Station_type  33024 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA92800,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122c6fc",
   "metadata": {},
   "source": [
    "### 93300_U_Aubervilliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d7efd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/93300_U_Aubervilliers | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '93300 - Aubervilliers'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '93300 - Aubervilliers'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93300_U_Aubervilliers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06544186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93300 - Aubervilliers</td>\n",
       "      <td>Urbain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2  \\\n",
       "0      2018/01/01 01:00:00+00   NaN   NaN  12.0 NaN  0.0   \n",
       "1      2018/01/01 02:00:00+00   NaN   NaN  13.0 NaN  0.0   \n",
       "2      2018/01/01 03:00:00+00   NaN   NaN  12.0 NaN  0.0   \n",
       "3      2018/01/01 04:00:00+00   NaN   NaN  14.0 NaN  0.0   \n",
       "4      2018/01/01 05:00:00+00   NaN   NaN  13.0 NaN  0.0   \n",
       "...                       ...   ...   ...   ...  ..  ...   \n",
       "43195  2022/12/05 20:00:00+00   NaN   NaN  26.7 NaN  NaN   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  26.6 NaN  NaN   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN   \n",
       "\n",
       "                Station_name Station_type  \n",
       "0      93300 - Aubervilliers       Urbain  \n",
       "1      93300 - Aubervilliers       Urbain  \n",
       "2      93300 - Aubervilliers       Urbain  \n",
       "3      93300 - Aubervilliers       Urbain  \n",
       "4      93300 - Aubervilliers       Urbain  \n",
       "...                      ...          ...  \n",
       "43195  93300 - Aubervilliers       Urbain  \n",
       "43196  93300 - Aubervilliers       Urbain  \n",
       "43197  93300 - Aubervilliers       Urbain  \n",
       "43198  93300 - Aubervilliers       Urbain  \n",
       "43199  93300 - Aubervilliers       Urbain  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA93300 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93300_U_Aubervilliers.csv\", index_col=0).copy()\n",
    "PA93300 = PA93300.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"AUB:CO\":\"CO\",\n",
    "    \"AUB:NO2\":\"NO2\",\n",
    "    \"AUB:SO2\":\"SO2\",\n",
    "    \"AUB:NO\":\"NO\",\n",
    "    \"AUB:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA93300 = PA93300.drop(columns=['CO', 'NO', 'NOX'])\n",
    "PA93300['PM25'] = float('NaN')\n",
    "PA93300['PM10'] = float('NaN')\n",
    "PA93300['O3'] = float('NaN')\n",
    "PA93300 = PA93300[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA93300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "adf10084",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA93300.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA93300.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09522122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, PM10: 100.0%, O3: 100.0%, SO2: 40.96%, NO2: 3.63%\n",
      "\n",
      "You might want to drop these features: PM25, PM10, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          0 non-null      float64\n",
      " 3   NO2           41633 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           25506 non-null  float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA93300,\"NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bef2b",
   "metadata": {},
   "source": [
    "### 93500_T_RN2_Pantin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cbf883e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list =  !find ../../data/Pollution/93500_T_RN2_Pantin | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '93500 - RN2 Pantin'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '93500 - RN2 Pantin'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93500_T_RN2_Pantin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "44d73a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01 01:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/01 02:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/01 03:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/01 04:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/01 05:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>2022/12/05 20:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>2022/12/05 21:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>2022/12/05 22:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>2022/12/05 23:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>2022/12/06 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93500 - RN2 Pantin</td>\n",
       "      <td>Traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date_time  PM25  PM10   NO2  O3  SO2        Station_name  \\\n",
       "0      2018/01/01 01:00:00+00   NaN  16.6  18.0 NaN  NaN  93500 - RN2 Pantin   \n",
       "1      2018/01/01 02:00:00+00   NaN   8.5  19.0 NaN  NaN  93500 - RN2 Pantin   \n",
       "2      2018/01/01 03:00:00+00   NaN   6.6  21.0 NaN  NaN  93500 - RN2 Pantin   \n",
       "3      2018/01/01 04:00:00+00   NaN  17.4  22.0 NaN  NaN  93500 - RN2 Pantin   \n",
       "4      2018/01/01 05:00:00+00   NaN  18.4  19.0 NaN  NaN  93500 - RN2 Pantin   \n",
       "...                       ...   ...   ...   ...  ..  ...                 ...   \n",
       "43195  2022/12/05 20:00:00+00   NaN  26.3  29.4 NaN  NaN  93500 - RN2 Pantin   \n",
       "43196  2022/12/05 21:00:00+00   NaN   NaN  27.8 NaN  NaN  93500 - RN2 Pantin   \n",
       "43197  2022/12/05 22:00:00+00   NaN   NaN   NaN NaN  NaN  93500 - RN2 Pantin   \n",
       "43198  2022/12/05 23:00:00+00   NaN   NaN   NaN NaN  NaN  93500 - RN2 Pantin   \n",
       "43199  2022/12/06 00:00:00+00   NaN   NaN   NaN NaN  NaN  93500 - RN2 Pantin   \n",
       "\n",
       "      Station_type  \n",
       "0          Traffic  \n",
       "1          Traffic  \n",
       "2          Traffic  \n",
       "3          Traffic  \n",
       "4          Traffic  \n",
       "...            ...  \n",
       "43195      Traffic  \n",
       "43196      Traffic  \n",
       "43197      Traffic  \n",
       "43198      Traffic  \n",
       "43199      Traffic  \n",
       "\n",
       "[43200 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA93500 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93500_T_RN2_Pantin.csv\", index_col=0).copy()\n",
    "PA93500 = PA93500.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"RN2:PM10\":\"PM10\",\n",
    "    \"RN2:NO2\":\"NO2\",\n",
    "    \"RN2:NO\":\"NO\",\n",
    "    \"RN2:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA93500 = PA93500.drop(columns=['NO', 'NOX'])\n",
    "PA93500['PM25'] = float('NaN')\n",
    "PA93500['O3'] = float('NaN')\n",
    "PA93500['SO2'] = float('NaN')\n",
    "PA93500 = PA93500[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA93500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a2a546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA93500.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA93500.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7239a8ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have : 5 features over 8 (0.62% of whole df) that include np.nan\n",
      "\n",
      "Have a look at these features (% of nan): PM25: 100.0%, O3: 100.0%, SO2: 100.0%, PM10: 2.35%, NO2: 2.02%\n",
      "\n",
      "You might want to drop these features: PM25, O3, SO2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43200 entries, 0 to 43199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date_time     43200 non-null  object \n",
      " 1   PM25          0 non-null      float64\n",
      " 2   PM10          42185 non-null  float64\n",
      " 3   NO2           42327 non-null  float64\n",
      " 4   O3            0 non-null      float64\n",
      " 5   SO2           0 non-null      float64\n",
      " 6   Station_name  43200 non-null  object \n",
      " 7   Station_type  43200 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "quick_check2(PA93500,\"NO2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa128a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paris DeepAir Project - Data Exploration\n",
    "\n",
    "Unité de mesure pour tous les polluants : mg/m3\n",
    "\n",
    "Polluants mesurés :\n",
    "- **CO** : monoxyde de carbone\n",
    "- **NO2** : dioxyde d'azote\n",
    "- **NO**: monoxyde d'azote\n",
    "- **NOX** : oxydes d'azote\n",
    "- **O3** : ozone\n",
    "- **PM 10** : particules\n",
    "- **PM 2,5** : particules fines\n",
    "- **SO2** : dioxyde de souffre\n",
    "\n",
    "Métaux mesurés:\n",
    "- **ETBEN**: ethylbenzene\n",
    "- **m+pXYL**: m+p-xylene\n",
    "- **oXYL**: o-xylene\n",
    "- **TOL**: toluene\n",
    "\n",
    "## Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../../data/pollution && ls -la\n",
    "\n",
    "## Useful functions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import pandas as pd\n",
    "\n",
    "def turbo_plot(X):\n",
    "    fig = plt.figure(constrained_layout=True,figsize=(15,120))\n",
    "    subfigs = fig.subfigures(X.shape[1], 1,squeeze=False,hspace=20)\n",
    "    for outerind, subfig in enumerate(subfigs.flat):\n",
    "        subfig.suptitle(f'Subfig {X.columns[outerind]}')\n",
    "        axs = subfig.subplots(1, 3)\n",
    "        sns.histplot(data = X, x = X.columns[outerind], kde=True, ax = axs[0])\n",
    "        sns.boxplot(data = X, x = X.columns[outerind], ax = axs[1])\n",
    "        qqplot(X[X.columns[outerind]],line='s',ax=axs[2])\n",
    "    return plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def mosaic_plot(df,X,y, ax=None):\n",
    "    default_colors =plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    cross = pd.crosstab(df[X],df[y])\n",
    "    couples = cross.unstack().index\n",
    "    props = lambda x: {'facecolor': default_colors[int(x[0])],'edgecolor':'w'}\n",
    "    labelizer = lambda k: {(str(cpl[0]),str(cpl[1])) : f'{cpl[0]}-{cpl[1]}\\n{round(cross.loc[cpl[1],cpl[0]]/cross.loc[:,cpl[0]].sum()*100,2)}%'  for cpl in couples}[k]\n",
    "    mosaic(df, [y, X],properties=props,labelizer = labelizer, ax=ax)\n",
    "    \n",
    "def turbo_plot(df, X, y,classification):\n",
    "    fig = plt.figure(constrained_layout=True,figsize=(15,round(10/3*df.shape[1])))\n",
    "    subfigs = fig.subfigures(X.shape[1], 1,squeeze=False,hspace=20)\n",
    "\n",
    "    for outerind, subfig in enumerate(subfigs.flat):\n",
    "        #plotting numerical features\n",
    "        if X[X.columns[outerind]].dtypes not in ['object','categorical','string'] and round(X[X.columns[outerind]].nunique()/df.shape[0]*100,2)>9:\n",
    "            subfig.suptitle(f'Subfig {X.columns[outerind]}')\n",
    "            axs = subfig.subplots(1, 4)\n",
    "            sns.histplot(data = X, x = X.columns[outerind], kde=True, ax = axs[0])\n",
    "            sns.boxplot(data = X, x = X.columns[outerind], ax = axs[1])\n",
    "            qqplot(X[X.columns[outerind]],line='s',ax=axs[2])\n",
    "            if classification: \n",
    "                sns.stripplot(data = X, x = y, y=X.columns[outerind], hue=y, ax = axs[3])\n",
    "            else: \n",
    "                sns.scatterplot(data = X, x = X.columns[outerind], y=y, ax = axs[3])\n",
    "\n",
    "        #plotting categorical features\n",
    "        else:\n",
    "            subfig.suptitle(f'Subfig {X.columns[outerind]}')\n",
    "            axs = subfig.subplots(1, 4)\n",
    "            sns.countplot(data = X, x = X.columns[outerind], ax = axs[0],order=X[X.columns[outerind]].value_counts().sort_values(ascending=False).index)\n",
    "            sns.countplot(data = X, x = X.columns[outerind], hue=y, ax = axs[1],order=X[X.columns[outerind]].value_counts().sort_values(ascending=False).index)\n",
    "            mosaic_plot(df,X.columns[outerind],df.survived.name,ax=axs[2])\n",
    "            if classification: \n",
    "                sns.stripplot(data = X, x = y, y=X.columns[outerind], hue=y, ax = axs[3])\n",
    "            else:\n",
    "                sns.scatterplot(data = X, x = X.columns[outerind], y=y, ax = axs[3])\n",
    "    return plt.show()\n",
    "\n",
    "def quick_check(df, target:str, classification=True, to_drop=None):\n",
    "    if target not in df.columns:\n",
    "        raise ValueError('target not in df.columns')\n",
    "    if not isinstance(target,str):\n",
    "        raise TypeError('target must str')\n",
    "    if to_drop:\n",
    "        if all(x in df.columns for x in to_drop):\n",
    "            raise ValueError('all elements in to_drop are not in df.columns')\n",
    "\n",
    "        if not isintance(to_drop,list) and isintance(to_drop,str):\n",
    "            to_drop=[to_drop]\n",
    "        else:\n",
    "            raise TypeError('to_drop type must be list of string')\n",
    "    \n",
    "    #Checking nan\n",
    "    check= round(df.isna().sum()/df.shape[0]*100,2).sort_values(ascending=False)\n",
    "    filtered = check[check>0]\n",
    "    print(f'You have : {len(filtered)} features over {len(check)} ({round(check[check>0].shape[0]/check.shape[0],2)}% of whole df) that include np.nan')    \n",
    "\n",
    "    #Features with nan\n",
    "    print(f'\\nHave a look at these features (% of nan): {\", \".join([f\"{i}: {str(v)}%\" for i,v in filtered.items()])}')\n",
    "\n",
    "    #Features to drop\n",
    "    super_drop = check[check>15]\n",
    "    print(f'\\nYou might want to drop these features: {\", \".join(super_drop.index)}')\n",
    "    imputation = df[check[(check>0) & (check<15)].index].dtypes\n",
    "    \n",
    "    print('\\n')\n",
    "    print(df.info())\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Let's have a look at all the features\")\n",
    "    X=df.drop(columns=(target if not to_drop else [target_name]+to_drop))\n",
    "    y=df[target]\n",
    "    turbo_plot(df, X,y,classification)\n",
    "\n",
    "def quick_check2(df, target:str, classification=True, to_drop=None):\n",
    "    if target not in df.columns:\n",
    "        raise ValueError('target not in df.columns')\n",
    "    if not isinstance(target,str):\n",
    "        raise TypeError('target must str')\n",
    "    if to_drop:\n",
    "        if all(x in df.columns for x in to_drop):\n",
    "            raise ValueError('all elements in to_drop are not in df.columns')\n",
    "\n",
    "        if not isintance(to_drop,list) and isintance(to_drop,str):\n",
    "            to_drop=[to_drop]\n",
    "        else:\n",
    "            raise TypeError('to_drop type must be list of string')\n",
    "    \n",
    "    #Checking nan\n",
    "    check= round(df.isna().sum()/df.shape[0]*100,2).sort_values(ascending=False)\n",
    "    filtered = check[check>0]\n",
    "    print(f'You have : {len(filtered)} features over {len(check)} ({round(check[check>0].shape[0]/check.shape[0],2)}% of whole df) that include np.nan')    \n",
    "\n",
    "    #Features with nan\n",
    "    print(f'\\nHave a look at these features (% of nan): {\", \".join([f\"{i}: {str(v)}%\" for i,v in filtered.items()])}')\n",
    "\n",
    "    #Features to drop\n",
    "    super_drop = check[check>15]\n",
    "    print(f'\\nYou might want to drop these features: {\", \".join(super_drop.index)}')\n",
    "    imputation = df[check[(check>0) & (check<15)].index].dtypes\n",
    "    \n",
    "    print('\\n')\n",
    "    print(df.info())\n",
    "\n",
    "## Per station\n",
    "\n",
    "#LOCAL_DATA_PATH_pollution = os.path.join(os.path.expanduser('~'), \"code\", \"TheLab75\", \"ParisDeepAirProject\", \"data\", \"pollution\")\n",
    "#LOCAL_DATA_PATH_pollution_merged = os.path.join(os.path.expanduser('~'), \"code\", \"TheLab75\", \"ParisDeepAirProject\", \"data\", \"pollution\", \"1_Merged\")\n",
    "#LOCAL_DATA_PATH_pollution_processed = os.path.join(os.path.expanduser('~'), \"code\", \"TheLab75\", \"ParisDeepAirProject\", \"data\", \"pollution\", \"2_Processed\")\n",
    "\n",
    "LOCAL_DATA_PATH_pollution = '../../data/pollution'\n",
    "LOCAL_DATA_PATH_pollution_merged = '../../data/pollution/1_Merged'\n",
    "LOCAL_DATA_PATH_pollution_processed = '../../data/pollution/2_Processed'\n",
    "\n",
    "### 75001_U_Halles\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75001_U_Halles | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75001 - Halles'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75001 - Halles'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "\n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75001_U_Halles.csv\")\n",
    "\n",
    "PA75001 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75001_U_Halles.csv\", index_col=0).copy()\n",
    "PA75001 = PA75001.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA01H:CO\":\"CO\",\n",
    "    \"PA01H:PM10\":\"PM10\",\n",
    "    \"PA01H:PM25\":\"PM25\",\n",
    "    \"PA01H:NO2\":\"NO2\",\n",
    "    \"PA01H:NO\":\"NO\",\n",
    "    \"PA01H:NOX\":\"NOX\",\n",
    "    \"PA01H:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75001 = PA75001.drop(columns=['CO', 'NO', 'NOX'])\n",
    "PA75001['SO2'] = float('NaN')\n",
    "PA75001 = PA75001[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75001\n",
    "\n",
    "PA75001.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75001.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75001,\"NO2\")\n",
    "\n",
    "### 75002_T_Opera\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75002_T_Opera | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75002 - Opera'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75002 - Opera'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75002_T_Opera.csv\")\n",
    "\n",
    "PA75002 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75002_T_Opera.csv\", index_col=0).copy()\n",
    "PA75002 = PA75002.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"OPERA:PM10\":\"PM10\",\n",
    "    \"OPERA:NO2\":\"NO2\",\n",
    "    \"OPERA:NO\":\"NO\",\n",
    "    \"OPERA:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75002 = PA75002.drop(columns=['NO', 'NOX'])\n",
    "PA75002['PM25'] = float('NaN')\n",
    "PA75002['O3'] = float('NaN')\n",
    "PA75002['SO2'] = float('NaN')\n",
    "PA75002 = PA75002[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75002\n",
    "\n",
    "PA75002.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75002.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75002,\"NO2\")\n",
    "\n",
    "### 75004_T_Quai_Celestins\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75004_T_Quai_Celestins | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75004 - Quai Celestins'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75004 - Quai Celestins'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75004_T_Quai_Celestins.csv\")\n",
    "\n",
    "PA75004 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75004_T_Quai_Celestins.csv\", index_col=0).copy()\n",
    "PA75004 = PA75004.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"CELES:NO2\":\"NO2\",\n",
    "    \"CELES:NO\":\"NO\",\n",
    "    \"CELES:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75004 = PA75004.drop(columns=['NO', 'NOX'])\n",
    "PA75004['PM25'] = float('NaN')\n",
    "PA75004['PM10'] = float('NaN')\n",
    "PA75004['O3'] = float('NaN')\n",
    "PA75004['SO2'] = float('NaN')\n",
    "PA75004 = PA75004[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75004\n",
    "\n",
    "PA75004.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75004.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75004,\"NO2\")\n",
    "\n",
    "### 75006_T_Bonap\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75006_T_Bonap | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75006 - Bonap'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75006 - Bonap'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75006_T_Bonap.csv\")\n",
    "\n",
    "PA75006 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75006_T_Bonap.csv\", index_col=0).copy()\n",
    "PA75006 = PA75006.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"BONAP:NO2\":\"NO2\",\n",
    "    \"BONAP:NO\":\"NO\",\n",
    "    \"BONAP:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75006 = PA75006.drop(columns=['NO', 'NOX'])\n",
    "PA75006['PM25'] = float('NaN')\n",
    "PA75006['PM10'] = float('NaN')\n",
    "PA75006['O3'] = float('NaN')\n",
    "PA75006['SO2'] = float('NaN')\n",
    "PA75006 = PA75006[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75006\n",
    "\n",
    "PA75006.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75006.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75006,\"NO2\")\n",
    "\n",
    "### 75007_Obs_Eiffel_3e\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75007_Obs_Eiffel_3e | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75007 - Eiffel_3e'\n",
    "base['Station_type'] = 'Observatoire'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75007 - Eiffel_3e'\n",
    "    new_df['Station_type'] = 'Observatoire'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_Obs_Eiffel_3e.csv\")\n",
    "\n",
    "PA75007_1 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_Obs_Eiffel_3e.csv\", index_col=0).copy()\n",
    "PA75007_1 = PA75007_1.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"EIFF3:NO2\":\"NO2\",\n",
    "    \"EIFF3:SO2\":\"SO2\",\n",
    "    \"EIFF3:NO\":\"NO\",\n",
    "    \"EIFF3:NOX\":\"NOX\",\n",
    "    \"EIFF3:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75007_1 = PA75007_1.drop(columns=['NO', 'NOX'])\n",
    "PA75007_1['PM25'] = float('NaN')\n",
    "PA75007_1['PM10'] = float('NaN')\n",
    "PA75007_1 = PA75007_1[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75007_1\n",
    "\n",
    "PA75007_1.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75007_1.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75007_1,\"NO2\")\n",
    "\n",
    "### 75007_U_Allee_R\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75007_U_Allee_R | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75007 - Allee_R'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75007 - Allee_R'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_U_Allee_R.csv\")\n",
    "\n",
    "PA75007_2 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75007_U_Allee_R.csv\", index_col=0).copy()\n",
    "PA75007_2 = PA75007_2.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA07:NO2\":\"NO2\",\n",
    "    \"PA07:NO\":\"NO\",\n",
    "    \"PA07:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75007_2 = PA75007_2.drop(columns=['NO', 'NOX'])\n",
    "PA75007_2['PM25'] = float('NaN')\n",
    "PA75007_2['PM10'] = float('NaN')\n",
    "PA75007_2['O3'] = float('NaN')\n",
    "PA75007_2['SO2'] = float('NaN')\n",
    "PA75007_2 = PA75007_2[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75007_2\n",
    "\n",
    "PA75007_2.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75007_2.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75007_2,\"NO2\")\n",
    "\n",
    "### 75008_T_Champs_Elysees\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75008_T_Champs_Elysees | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75008 - Champs Elysees'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75008 - Champs Elysees'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75008_T_Champs_Elysees.csv\")\n",
    "\n",
    "PA75008 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75008_T_Champs_Elysees.csv\", index_col=0).copy()\n",
    "PA75008 = PA75008.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"ELYS:PM10\":\"PM10\",\n",
    "    \"ELYS:NO2\":\"NO2\",\n",
    "    \"ELYS:NO\":\"NO\",\n",
    "    \"ELYS:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75008 = PA75008.drop(columns=['NO', 'NOX'])\n",
    "PA75008['PM25'] = float('NaN')\n",
    "PA75008['O3'] = float('NaN')\n",
    "PA75008['SO2'] = float('NaN')\n",
    "PA75008 = PA75008[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75008\n",
    "\n",
    "PA75008.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75008.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75008,\"NO2\")\n",
    "\n",
    "### 75009_T_Haussmann\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75009_T_Haussmann | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75009 - Haussmann'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75009 - Haussmann'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75009_T_Haussmann.csv\")\n",
    "\n",
    "PA75009 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75009_T_Haussmann.csv\", index_col=0).copy()\n",
    "PA75009 = PA75009.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"HAUS:PM10\":\"PM10\",\n",
    "    \"HAUS:PM25\":\"PM25\",\n",
    "    \"HAUS:NO2\":\"NO2\",\n",
    "    \"HAUS:NO\":\"NO\",\n",
    "    \"HAUS:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75009 = PA75009.iloc[:, [0, 7, 1, 2, 3, 4, 5, 6]]\n",
    "PA75009 = PA75009.drop(columns=['NO', 'NOX'])\n",
    "PA75009['O3'] = float('NaN')\n",
    "PA75009['SO2'] = float('NaN')\n",
    "PA75009 = PA75009[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75009\n",
    "\n",
    "PA75009.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75009.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75009,\"NO2\")\n",
    "\n",
    "### 75012_T_Bd_Soult\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75012_T_Bd_Soult | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75012 - Bd Soult'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75012 - Bd Soult'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_Bd_Soult.csv\")\n",
    "\n",
    "PA75012_1 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_Bd_Soult.csv\", index_col=0).copy()\n",
    "PA75012_1 = PA75012_1.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"SOULT:NO2\":\"NO2\",\n",
    "    \"SOULT:NO\":\"NO\",\n",
    "    \"SOULT:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75012_1 = PA75012_1.drop(columns=['NO', 'NOX'])\n",
    "PA75012_1['PM25'] = float('NaN')\n",
    "PA75012_1['PM10'] = float('NaN')\n",
    "PA75012_1['O3'] = float('NaN')\n",
    "PA75012_1['SO2'] = float('NaN')\n",
    "PA75012_1 = PA75012_1[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75012_1\n",
    "\n",
    "PA75012_1.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75012_1.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75012_1,\"NO2\")\n",
    "\n",
    "### 75012_T_BP_Est\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75012_T_BP_Est | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75012 - BP Est'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75012 - BP Est'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_BP_Est.csv\")\n",
    "\n",
    "PA75012_2 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_T_BP_Est.csv\", index_col=0).copy()\n",
    "PA75012_2 = PA75012_2.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"BP_EST:PM10\":\"PM10\",\n",
    "    \"BP_EST:PM25\":\"PM25\",\n",
    "    \"BP_EST:NO2\":\"NO2\",\n",
    "    \"BP_EST:NO\":\"NO\",\n",
    "    \"BP_EST:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75012_2 = PA75012_2.drop(columns=['NO', 'NOX'])\n",
    "PA75012_2['O3'] = float('NaN')\n",
    "PA75012_2['SO2'] = float('NaN')\n",
    "PA75012_2 = PA75012_2[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75012_2\n",
    "\n",
    "PA75012_2.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75012_2.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75012_2,\"NO2\")\n",
    "\n",
    "### 75012_U_Rue_BaL\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75012_U_Rue_BaL | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75012 - Rue BaL'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75012 - Rue BaL'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_U_Rue_BaL.csv\")\n",
    "\n",
    "PA75012_3 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75012_U_Rue_BaL.csv\", index_col=0).copy()\n",
    "PA75012_3 = PA75012_3.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA12:NO2\":\"NO2\",\n",
    "    \"PA12:NO\":\"NO\",\n",
    "    \"PA12:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75012_3 = PA75012_3.drop(columns=['NO', 'NOX'])\n",
    "PA75012_3['PM25'] = float('NaN')\n",
    "PA75012_3['PM10'] = float('NaN')\n",
    "PA75012_3['O3'] = float('NaN')\n",
    "PA75012_3['SO2'] = float('NaN')\n",
    "PA75012_3 = PA75012_3[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75012_3\n",
    "\n",
    "PA75012_3.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75012_3.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75012_3,\"NO2\")\n",
    "\n",
    "### 75013_U_Eastman\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75013_U_Eastman | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75013 - Eastman'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75013 - Eastman'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75013_U_Eastman.csv\")\n",
    "\n",
    "PA75013 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75013_U_Eastman.csv\", index_col=0).copy()\n",
    "PA75013 = PA75013.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA13:NO2\":\"NO2\",\n",
    "    \"PA13:NO\":\"NO\",\n",
    "    \"PA13:NOX\":\"NOX\",\n",
    "    \"PA13:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75013 = PA75013.drop(columns=['NO', 'NOX'])\n",
    "PA75013['PM25'] = float('NaN')\n",
    "PA75013['PM10'] = float('NaN')\n",
    "PA75013['SO2'] = float('NaN')\n",
    "PA75013 = PA75013[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75013\n",
    "\n",
    "PA75013.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75013.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75013,\"NO2\")\n",
    "\n",
    "### 75014_T_Basch\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75014_T_Basch | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75014 - Basch'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75014 - Basch'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75014_T_Basch.csv\")\n",
    "\n",
    "PA75014 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75014_T_Basch.csv\", index_col=0).copy()\n",
    "PA75014 = PA75014.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"BASCH:CO\":\"CO\",\n",
    "    \"BASCH:PM10\":\"PM10\",\n",
    "    \"BASCH:NO2\":\"NO2\",\n",
    "    \"BASCH:NO\":\"NO\",\n",
    "    \"BASCH:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75014 = PA75014.drop(columns=['CO', 'NO', 'NOX'])\n",
    "PA75014['PM25'] = float('NaN')\n",
    "PA75014['O3'] = float('NaN')\n",
    "PA75014['SO2'] = float('NaN')\n",
    "PA75014 = PA75014[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75014\n",
    "\n",
    "PA75014.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75014.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75014,\"NO2\")\n",
    "\n",
    "### 75015_U_Lenglen\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75015_U_Lenglen | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75015 - Lenglen'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75015 - Lenglen'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75015_U_Lenglen.csv\")\n",
    "\n",
    "PA75015 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75015_U_Lenglen.csv\", index_col=0).copy()\n",
    "PA75015 = PA75015.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA15L:PM10\":\"PM10\",\n",
    "    \"PA15L:NO2\":\"NO2\",\n",
    "    \"PA15L:NO\":\"NO\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75015 = PA75015.drop(columns=['NO'])\n",
    "PA75015['PM25'] = float('NaN')\n",
    "PA75015['O3'] = float('NaN')\n",
    "PA75015['SO2'] = float('NaN')\n",
    "PA75015 = PA75015[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75015\n",
    "\n",
    "PA75015.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75015.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75015,\"NO2\")\n",
    "\n",
    "### 75016_T_Porte_Auteuil\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75016_T_Porte_Auteuil | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75016 - Porte Auteuil'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75016 - Porte Auteuil'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75016_T_Porte_Auteuil.csv\")\n",
    "\n",
    "PA75016 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75016_T_Porte_Auteuil.csv\", index_col=0).copy()\n",
    "PA75016 = PA75016.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"AUT:CO\":\"CO\",\n",
    "    \"AUT:PM10\":\"PM10\",\n",
    "    \"AUT:PM25\":\"PM25\",\n",
    "    \"AUT:NO2\":\"NO2\",\n",
    "    \"AUT:SO2\":\"SO2\",\n",
    "    \"AUT:ETBEN\":\"ETBEN\",\n",
    "    \"AUT:m+pXYL\":\"m+pXYL\",\n",
    "    \"AUT:NO\":\"NO\",\n",
    "    \"AUT:oXYL\":\"oXYL\",\n",
    "    \"AUT:NOX\":\"NOX\",\n",
    "    \"AUT:TOL\":\"TOL\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75016 = PA75016.drop(columns=['CO', 'NO', 'NOX', 'ETBEN', 'm+pXYL', 'oXYL', 'TOL'])\n",
    "PA75016['O3'] = float('NaN')\n",
    "PA75016 = PA75016[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75016\n",
    "\n",
    "PA75016.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75016.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75016,\"NO2\")\n",
    "\n",
    "### 75018_U_Flocon\n",
    "\n",
    "file_list =  !find ../../data/Pollution/75018_U_Flocon | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '75018 - Flocon'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '75018 - Flocon'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75018_U_Flocon.csv\")\n",
    "\n",
    "PA75018 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/75018_U_Flocon.csv\", index_col=0).copy()\n",
    "PA75018 = PA75018.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"PA18:PM10\":\"PM10\",\n",
    "    \"PA18:NO2\":\"NO2\",\n",
    "    \"PA18:NO\":\"NO\",\n",
    "    \"PA18:NOX\":\"NOX\",\n",
    "    \"PA18:O3\":\"O3\",\n",
    "    \"PA18:PM25\":\"PM25\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA75018 = PA75018.iloc[:, [0, 8, 1, 2, 3, 4, 5, 6, 7]]\n",
    "PA75018 = PA75018.drop(columns=['NO', 'NOX'])\n",
    "PA75018['SO2'] = float('NaN')\n",
    "PA75018 = PA75018[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA75018\n",
    "\n",
    "PA75018.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA75018.csv\", index=False)\n",
    "\n",
    "quick_check2(PA75018,\"NO2\")\n",
    "\n",
    "### 92220_U_Neuilly\n",
    "\n",
    "file_list =  !find ../../data/Pollution/92220_U_Neuilly | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '92220 - Neuilly'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '92220 - Neuilly'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92220_U_Neuilly.csv\")\n",
    "\n",
    "PA92220 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92220_U_Neuilly.csv\", index_col=0).copy()\n",
    "PA92220 = PA92220.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"NEUIL:NO2\":\"NO2\",\n",
    "    \"NEUIL:SO2\":\"SO2\",\n",
    "    \"NEUIL:NO\":\"NO\",\n",
    "    \"NEUIL:NOX\":\"NOX\",\n",
    "    \"NEUIL:O3\":\"O3\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA92220 = PA92220.drop(columns=['NO', 'NOX'])\n",
    "PA92220['PM25'] = float('NaN')\n",
    "PA92220['PM10'] = float('NaN')\n",
    "PA92220 = PA92220[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA92220\n",
    "\n",
    "PA92220.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA92220.csv\", index=False)\n",
    "\n",
    "quick_check2(PA92220,\"NO2\")\n",
    "\n",
    "### 92800_U_La_Defense\n",
    "\n",
    "file_list =  !find ../../data/Pollution/92800_U_La_Defense | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '92800 - La Defense'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '92800 - La Defense'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92800_U_La_Defense.csv\")\n",
    "\n",
    "PA92800 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/92800_U_La_Defense.csv\", index_col=0).copy()\n",
    "PA92800 = PA92800.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"DEF:PM10\":\"PM10\",\n",
    "    \"DEF:PM25\":\"PM25\",\n",
    "    \"DEF:NO2\":\"NO2\",\n",
    "    \"DEF:NO\":\"NO\",\n",
    "    \"DEF:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA92800 = PA92800.iloc[:, [0, 7, 1, 2, 3, 4, 5, 6]]\n",
    "PA92800 = PA92800.drop(columns=['NO', 'NOX'])\n",
    "PA92800['O3'] = float('NaN')\n",
    "PA92800['SO2'] = float('NaN')\n",
    "PA92800 = PA92800[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA92800\n",
    "\n",
    "PA92800.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA92800.csv\", index=False)\n",
    "\n",
    "quick_check2(PA92800,\"NO2\")\n",
    "\n",
    "### 93300_U_Aubervilliers\n",
    "\n",
    "file_list =  !find ../../data/Pollution/93300_U_Aubervilliers | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '93300 - Aubervilliers'\n",
    "base['Station_type'] = 'Urbain'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '93300 - Aubervilliers'\n",
    "    new_df['Station_type'] = 'Urbain'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93300_U_Aubervilliers.csv\")\n",
    "\n",
    "PA93300 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93300_U_Aubervilliers.csv\", index_col=0).copy()\n",
    "PA93300 = PA93300.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"AUB:CO\":\"CO\",\n",
    "    \"AUB:NO2\":\"NO2\",\n",
    "    \"AUB:SO2\":\"SO2\",\n",
    "    \"AUB:NO\":\"NO\",\n",
    "    \"AUB:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA93300 = PA93300.drop(columns=['CO', 'NO', 'NOX'])\n",
    "PA93300['PM25'] = float('NaN')\n",
    "PA93300['PM10'] = float('NaN')\n",
    "PA93300['O3'] = float('NaN')\n",
    "PA93300 = PA93300[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA93300\n",
    "\n",
    "PA93300.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA93300.csv\", index=False)\n",
    "\n",
    "quick_check2(PA93300,\"NO2\")\n",
    "\n",
    "### 93500_T_RN2_Pantin\n",
    "\n",
    "file_list =  !find ../../data/Pollution/93500_T_RN2_Pantin | grep .csv\n",
    "file_list = file_list.sort()\n",
    "\n",
    "base = pd.read_csv(file_list[0], index_col=0).copy()\n",
    "base = base.drop(columns=\"OBJECTID\")\n",
    "base['Station_name'] = '93500 - RN2 Pantin'\n",
    "base['Station_type'] = 'Traffic'\n",
    "base = base[5:]\n",
    "\n",
    "for i in file_list[1:] :\n",
    "    new_df = pd.read_csv(i,index_col=0).copy()\n",
    "    new_df = new_df.drop(columns=\"OBJECTID\")\n",
    "    new_df['Station_name'] = '93500 - RN2 Pantin'\n",
    "    new_df['Station_type'] = 'Traffic'\n",
    "    new_df = new_df[5:]\n",
    "    base = pd.concat([base, new_df])\n",
    "\n",
    "base = base.reset_index()\n",
    "    \n",
    "base.to_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93500_T_RN2_Pantin.csv\")\n",
    "\n",
    "PA93500 = pd.read_csv(f\"{LOCAL_DATA_PATH_pollution_merged}/93500_T_RN2_Pantin.csv\", index_col=0).copy()\n",
    "PA93500 = PA93500.rename(columns={\n",
    "    \"index\":\"Date_time\",\n",
    "    \"RN2:PM10\":\"PM10\",\n",
    "    \"RN2:NO2\":\"NO2\",\n",
    "    \"RN2:NO\":\"NO\",\n",
    "    \"RN2:NOX\":\"NOX\",\n",
    "    \"Station_name\":\"Station_name\",\n",
    "    \"Station_type\":\"Station_type\"}, errors=\"raise\")\n",
    "PA93500 = PA93500.drop(columns=['NO', 'NOX'])\n",
    "PA93500['PM25'] = float('NaN')\n",
    "PA93500['O3'] = float('NaN')\n",
    "PA93500['SO2'] = float('NaN')\n",
    "PA93500 = PA93500[['Date_time', 'PM25', 'PM10', 'NO2', 'O3', 'SO2', 'Station_name', 'Station_type']]\n",
    "PA93500\n",
    "\n",
    "PA93500.to_csv(f\"{LOCAL_DATA_PATH_pollution_processed}/PA93500.csv\", index=False)\n",
    "\n",
    "quick_check2(PA93500,\"NO2\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
